{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os, sys, re, math, functools, itertools, collections, time, pickle, io\n",
    "import cv2\n",
    "sys.path.append('/home/jupyter/code')\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import colors as mcolors\n",
    "from skimage.filters import threshold_otsu\n",
    "from PIL import Image, ImageSequence\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from IPython.display import HTML\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utility import densenet_regression, linear_regression, power_series, neighbor_cor, cosine_similarity\n",
    "from utility import weighted_mse_loss, empty_cache, detect_outliers, svd, get_label_image\n",
    "from visualization import plot_tensor, imshow, plot_cdf, plot_3d_scatter, plot_image, plot_images, plot_curves\n",
    "from visualization import plot_hist, get_image, make_video, make_3d_video, plot_trace, plot_image_label_overlay\n",
    "from models import UNet, MultiConv, get_mask, get_bg_mat, restore_image_noise2self\n",
    "from nmf import non_negative_factorization\n",
    "from pmd import denoise, total_variation, second_order_difference, pmd_compress, rank_one_decomposition \n",
    "from pmd import get_threshold\n",
    "from optical_electrophysiology import load_mat, detrend, extract_super_pixels, get_submat_traces, prep_train_data\n",
    "from optical_electrophysiology import detrend_high_magnification, load_file, get_size_from_txt\n",
    "from optical_electrophysiology import refine_segmentation, detrend_linear, extract_single_trace, extract_traces\n",
    "from train import train_model, step_decompose, rank_k_decompose\n",
    "\n",
    "use_gpu = True\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "colors = sorted(mcolors.CSS4_COLORS)\n",
    "random.shuffle(colors)\n",
    "colors = sorted(mcolors.BASE_COLORS) + colors\n",
    "bad_colors = '|'.join(['white', 'light', 'gray', 'mint', 'rebeccapurple', 'steelblue', 'darkkhaki', 'ivory',  \n",
    "                       'cornsilk', 'honeydew', 'peru', 'alice', 'azure'])\n",
    "colors = [i for i in colors if i!='w' and not re.search(bad_colors, i)]\n",
    "get_cm = lambda sel_colors: LinearSegmentedColormap.from_list('cmap_name', sel_colors, N=len(sel_colors))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 20, 15\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# dataset_name = 'low_mag_cultured_neurons_2015-12-18'\n",
    "# dataset_name = 'pooled_ipsc_2018-09-17'\n",
    "# dataset_name = 'pooled_ipsc_2018-12-07'\n",
    "# dataset_name = 'high_mag_adrenal_cortex'\n",
    "# dataset_name = 'high_mag_beta_cell'\n",
    "# dataset_name = 'low_mag_beta_cell'\n",
    "plot = False\n",
    "figsize = (20, 15)\n",
    "random_file = True\n",
    "no_detrend = False\n",
    "\n",
    "\n",
    "def predict(x, model, filepath=None, return_detached=True, device=torch.device('cuda')):\n",
    "    if filepath is not None and os.path.exists(filepath):\n",
    "        model.load_state_dict(torch.load(filepath))\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "    if return_detached:\n",
    "        y = y.detach()\n",
    "    for k in [k for k in locals().keys if k!='y']:\n",
    "        del locals()[k]\n",
    "    torch.cuda.empty_cache()\n",
    "    return y\n",
    "    \n",
    "def denoise_trace(trace, model=None, filepath='checkpoints/denoise_trace.pt', return_detached=True, \n",
    "                  device=torch.device('cuda')):\n",
    "    if model is None:\n",
    "        model = UNet(in_channels=1, num_classes=1, out_channels=[8, 16, 32], num_conv=2, \n",
    "                     n_dim=1, kernel_size=3).to(device)\n",
    "        model.load_state_dict(torch.load(filepath))\n",
    "    with torch.no_grad():\n",
    "        mean = trace.mean()\n",
    "        std = trace.std()\n",
    "        pred = model((trace-mean)/std)\n",
    "        pred = model(pred)\n",
    "        pred = pred * std + mean\n",
    "    if return_detached:\n",
    "        pred = pred.detach()\n",
    "    for k in [k for k in locals().keys() if k!='pred']:\n",
    "        del locals()[k]\n",
    "    torch.cuda.empty_cache()\n",
    "    return pred\n",
    "\n",
    "def denoise_3d(mat, model=None, filepath='checkpoints/3d_denoise.pt', return_detached=True, \n",
    "               batch_size=5000, device=torch.device('cuda')):\n",
    "    if model is None:\n",
    "        model = UNet(in_channels=1, num_classes=1, out_channels=[4, 8, 16], num_conv=2, n_dim=3, \n",
    "                     kernel_size=[3, 3, 3], same_shape=True).to(device)\n",
    "        model.load_state_dict(torch.load(filepath))\n",
    "    with torch.no_grad():\n",
    "        num_batches = (mat.size(0) + batch_size - 1)//batch_size\n",
    "        mat = torch.cat([model(mat[batch_size*i:batch_size*(i+1)]) for i in range(num_batches)], dim=0)\n",
    "    if return_detached:\n",
    "        mat = mat.detach()\n",
    "    for k in [k for k in locals().keys() if k!='mat']:\n",
    "        del locals()[k]\n",
    "    torch.cuda.empty_cache()\n",
    "    return mat\n",
    "\n",
    "def attention_map(mat, model=None, filepath='checkpoints/segmentation_count_hardmask.pt', \n",
    "                  batch_size=5000, return_detached=True, device=torch.device('cuda')):\n",
    "    if model is None:\n",
    "        model = UNet(in_channels=1, num_classes=1, out_channels=[4, 8, 16], num_conv=2, n_dim=3, \n",
    "                     kernel_size=[3, 3, 3], same_shape=True).to(device)\n",
    "        model.load_state_dict(torch.load(filepath))\n",
    "    nrow, ncol = mat.shape[1:]\n",
    "    if batch_size*nrow*ncol > 1e7:\n",
    "        batch_size = int(1e7 / (nrow*ncol))\n",
    "    with torch.no_grad():\n",
    "        num_batches = (mat.size(0) + batch_size - 1)//batch_size\n",
    "        mat = torch.cat([model(mat[batch_size*i:batch_size*(i+1)]) for i in range(num_batches)], dim=0).mean(0)\n",
    "    if return_detached:\n",
    "        mat = mat.detach()\n",
    "    for k in [k for k in locals().keys() if k!='mat']:\n",
    "        del locals()[k]\n",
    "    torch.cuda.empty_cache()\n",
    "    return mat\n",
    "\n",
    "def refine_one_label(submat, min_pixels=50, return_traces=False, percentile=50):\n",
    "    soft_attention = attention_map(submat)\n",
    "    label_image, regions = get_label_image(soft_attention, min_pixels=min_pixels)\n",
    "    if return_traces:\n",
    "        submats, traces = extract_traces(submat, softmask=soft_attention, label_image=label_image, regions=regions, \n",
    "                                         percentile=percentile)\n",
    "        return submats, traces, soft_attention, label_image, regions\n",
    "    else:\n",
    "        return label_image\n",
    "\n",
    "def refine_segmentation(submats, regions, label_image, min_pixels=50, connectivity=None):\n",
    "    for label_idx in range(1, len(submats)+1):\n",
    "        submat = submats[label_idx-1]\n",
    "        minr, minc, maxr, maxc = regions[label_idx-1].bbox\n",
    "        img = refine_one_label(submat, min_pixels=min_pixels)\n",
    "        label_image[minr:maxr, minc:maxc] = img\n",
    "    from skimage.measure import label, regionprops\n",
    "    label_image = label(label_image>0, connectivity=connectivity)\n",
    "    regions = regionprops(label_image)\n",
    "    return label_image, regions\n",
    "\n",
    "def zoom_in(seq, batch_size=700, seq2=None, figsize=(15, 10), label1='seq1', label2='seq2'):\n",
    "    if isinstance(seq, torch.Tensor):\n",
    "        seq = seq.detach().cpu().numpy()\n",
    "        if seq2 is not None and isinstance(seq2, torch.Tensor):\n",
    "            seq2 = seq2.detach().cpu().numpy()\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(seq, 'b-', alpha=0.5, label=label1)\n",
    "    if seq2 is not None:\n",
    "        plt.plot(seq2, 'k--', alpha=0.5, label=label2)\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "    num_batches = (len(seq)+batch_size-1) // batch_size\n",
    "    for i in range(num_batches):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(seq[i*batch_size:(i+1)*batch_size], 'b-', alpha=1, label='seq1')\n",
    "        if seq2 is not None:\n",
    "            plt.plot(seq2[i*batch_size:(i+1)*batch_size], 'k--', alpha=0.5, label='seq2')\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "def plot_pca_result(W, H, percentile=99.5, cor_map=None, title=None):\n",
    "    from skimage.measure import regionprops\n",
    "    num = W.shape[0]\n",
    "    label_image = np.zeros((512, 180))\n",
    "    for i in range(num):\n",
    "        mask = np.abs(W[i])\n",
    "        label_image[mask > np.percentile(mask, percentile)] = i+1\n",
    "    label_image = label_image.T.astype('int')\n",
    "    regions = regionprops(label_image)\n",
    "    imshow(label_image)\n",
    "    plot_image_label_overlay(np.zeros((180, 512)) if cor_map is None else cor_map, label_image=label_image, regions=regions)\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    for i in range(num):\n",
    "        trace = H[-700:, i] + i*0.5\n",
    "        plt.plot(trace, label=i+1)\n",
    "    plt.legend()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/jupyter/disk/data/sami/Adrenal Cortex'\n",
    "filepath = f'{folder}/floxopatch_glomerulous_20hz.tif'\n",
    "im = Image.open(filepath)\n",
    "array = np.array([np.array(page) for page in ImageSequence.Iterator(im)])\n",
    "mat = torch.from_numpy(array.astype('float32')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_result(np.transpose(A, (2,0,1)), C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_result(f'{folder}/pca_ica_out.mat')\n",
    "A = res['out'] \n",
    "C = res['vica']\n",
    "for i in range(A.shape[-1]):\n",
    "    imshow(A[:, :, i])\n",
    "    plt.plot(C[:, i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN attention pooling: prior (location + correlation) + dynamic distance \n",
    "\n",
    "# Train a local transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    r\"\"\"Applies two convolutions over an input of signal composed of several input planes.\n",
    "    \n",
    "    Args:\n",
    "        in_channels (int): Number of input channels\n",
    "    \n",
    "    Shape:\n",
    "        Input: :math:`(N, in_channels, H, W)`\n",
    "        Output: :math:`(N, out_channels, H_{out}, W_{out})`\n",
    "    \n",
    "    Attributes:\n",
    "        weight (Tensor): \n",
    "        bias (Tensor): \n",
    "        \n",
    "    Examples::\n",
    "    \n",
    "        >>> x = torch.randn(2, 3, 5, 7)\n",
    "        >>> model = MultiConv(3, 11)\n",
    "        >>> model(x).shape\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, n_dim=2, kernel_size=3, stride=1, dilation=1, groups=1, bias=True, padding=True,\n",
    "                 padding_mode='replicate', normalization='layer_norm', activation=nn.LeakyReLU(negative_slope=0.01, inplace=True)):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.padding_mode = padding_mode\n",
    "        self.n_dim = n_dim\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = [kernel_size] * n_dim\n",
    "        if isinstance(dilation, int):\n",
    "            dilation = [dilation] * n_dim\n",
    "        if isinstance(stride, int):\n",
    "            self.stride = [stride] * n_dim\n",
    "        self.effective_kernel_size = [dilation[i] * (kernel_size[i]-1) + 1 for i in range(n_dim)]\n",
    "        if n_dim == 3:\n",
    "            Conv = nn.Conv3d\n",
    "        elif n_dim == 2:\n",
    "            Conv = nn.Conv2d\n",
    "        elif n_dim == 1:\n",
    "            Conv = nn.Conv1d\n",
    "        self.conv = Conv(in_channels, out_channels, kernel_size, stride=stride, padding=0, dilation=dilation, groups=1, bias=bias, \n",
    "                         padding_mode='zeros')\n",
    "        if normalization == 'layer_norm':\n",
    "            num_groups = 1\n",
    "        elif normalization == 'instance_norm':\n",
    "            num_groups = out_channels\n",
    "        elif isinstance(normalization, int):\n",
    "            num_groups = normalization\n",
    "        else:\n",
    "            raise ValueError(f'normalization = {normalization} not defined!')\n",
    "        self.norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for _ in range(0, self.n_dim + 2 - x.ndim, 1):\n",
    "            x = x.unsqueeze(0)\n",
    "        if self.padding:\n",
    "            padding = []\n",
    "            for L, k, s in zip(x.shape[2:], self.effective_kernel_size, self.stride):\n",
    "                if k >= s:\n",
    "                    tmp = L - math.floor((L-k)/s) * s\n",
    "                    if tmp == 0:\n",
    "                        padding.append(0)\n",
    "                    else:\n",
    "                        padding.append(s+k-tmp)\n",
    "                else:\n",
    "                    padding.append(0)\n",
    "            expanded_padding = []\n",
    "            for p in padding:\n",
    "                expanded_padding = [(p+1)//2, p//2] + expanded_padding\n",
    "            if sum(expanded_padding) > 0:\n",
    "                x = nn.functional.pad(x, expanded_padding, mode=self.padding_mode)\n",
    "        x = self.activation(self.norm(self.conv(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_targets=1, in_channels=1, out_channels=[8, 16, 32, 64, 128], kernel_sizes=[3, 5, 5, 5, 5], \n",
    "                 strides=[1, 1, 2, 2, 2], dilations=[1, 1, 2, 3, 3], n_dim=1, padding=True):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.num_layers = len(out_channels)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            self.layers.append(\n",
    "                ConvLayer(in_channels=in_channels if i==0 else out_channels[i-1], out_channels=out_channels[i], n_dim=n_dim, \n",
    "                          kernel_size=kernel_sizes[i], stride=strides[i], dilation=dilations[i], padding=padding)\n",
    "            )\n",
    "        self.linear = nn.Linear(out_channels[-1], num_targets)\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.layers[i](x)\n",
    "        x = self.linear(x.mean(-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(padding=False)\n",
    "cnt = 0\n",
    "for n, p in model.named_parameters():\n",
    "    cnt += p.numel()\n",
    "print(cnt)\n",
    "x = torch.randn(300, 1, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'checkpoints/segmentation_count_hardmask.pt'\n",
    "model = UNet(in_channels=1, num_classes=1, out_channels=[4, 8, 16], num_conv=2, n_dim=3, \n",
    "             kernel_size=[3, 3, 3], same_shape=True).to(device)\n",
    "model.load_state_dict(torch.load(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/tma/projects/optical_profiling/adam'\n",
    "exp_ids = [f for f in os.listdir(folder) if os.path.isdir(f'{folder}/{f}')]\n",
    "exp_id = exp_ids[0]\n",
    "f = open(f'{folder}/{exp_id}/experimental_parameters.txt', 'r')\n",
    "param_str = f.read().split('\\n')\n",
    "f.close()\n",
    "params = [s.split('\\t') for s in param_str if re.search('Horizontal pixel|Vertical pixel', s)]\n",
    "for p in params:\n",
    "    if re.search('Horizontal pixel', p[0]):\n",
    "        ncol = int(p[1])\n",
    "    elif re.search('Vertical pixel', p[0]):\n",
    "        nrow = int(p[1])\n",
    "mat = load_file(f'{folder}/{exp_id}/Sq_camera.bin', size=(-1, nrow, ncol))\n",
    "mat = detrend_linear(mat[1000:])\n",
    "cor_map = torch.stack([neighbor_cor(mat=mat[4000*i:4000*(i+1)], neighbors=8, choice='mean', nonnegative=True) \n",
    "           for i in range(16)], dim=0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/jupyter/disk/data/sami/low_mag_cultured_neurons/'\n",
    "with open(os.path.join(folder, 'meta_data.pkl'), 'rb') as f:\n",
    "    meta_data = pickle.load(f)\n",
    "    exp_id_dict = {s[:10]:s for s in sorted(meta_data)}\n",
    "all_exp_ids = sorted(meta_data)\n",
    "trace_idx = {n: i for i, n in enumerate(sorted(meta_data))}\n",
    "\n",
    "if not (os.path.exists('train_data/label_images.npz') and os.path.exists('train_data/traces.pkl')):\n",
    "    all_traces = []\n",
    "    all_images = []\n",
    "    cor_maps = []\n",
    "    for exp_id in sorted(meta_data):\n",
    "        print(exp_id)\n",
    "        mat = load_mat(exp_id, meta_data, folder, device=device)\n",
    "        # the first frame of 7500 frames is missing; skip the initial 50 frames\n",
    "        mat_list = [mat[799+750*i:1499+750*i] for i in range(9)]\n",
    "        train_idx = list(range(200)) + list(range(550, 700))\n",
    "        mat_adj = [detrend_linear(mat=m, train_idx=train_idx) for m in mat_list]\n",
    "        mat = torch.cat(mat_adj, dim=0)\n",
    "        del mat_adj, mat_list\n",
    "        torch.cuda.empty_cache()\n",
    "        cor_map = neighbor_cor(mat=mat, neighbors=8, choice='mean', nonnegative=True)\n",
    "        label_image, regions = get_label_image(cor_map, min_pixels=50)\n",
    "        submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "        label_image, regions = refine_segmentation(submats, regions, label_image)\n",
    "        submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "        all_traces.append(torch.stack(traces, dim=0).cpu().numpy())\n",
    "        all_images.append(label_image)\n",
    "        cor_maps.append(cor_map.detach().cpu().numpy())\n",
    "    all_images = np.stack(all_images, axis=0)\n",
    "    cor_maps = np.stack(cor_maps, axis=0)\n",
    "    np.savez('train_data/label_images.npz', all_images=all_images, cor_maps=cor_maps)\n",
    "    with open('train_data/traces.pkl', 'wb') as f:\n",
    "        pickle.dump(all_traces, f)\n",
    "npzfile = np.load('train_data/label_images.npz')\n",
    "all_images = npzfile['all_images']\n",
    "cor_maps = npzfile['cor_maps']\n",
    "with open('train_data/traces.pkl', 'rb') as f:\n",
    "    all_traces = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'D1_FOV3_W2_at135105'\n",
    "mat = load_mat(exp_id, meta_data, folder, device=device)\n",
    "# the first frame of 7500 frames is missing; skip the initial 50 frames\n",
    "mat_list = [mat[799+750*i:1499+750*i] for i in range(9)]\n",
    "train_idx = list(range(200)) + list(range(550, 700))\n",
    "mat_adj = [detrend_linear(mat=m, train_idx=train_idx) for m in mat_list]\n",
    "mat = torch.cat(mat_adj, dim=0)\n",
    "del mat_adj, mat_list\n",
    "torch.cuda.empty_cache()\n",
    "cor_map = neighbor_cor(mat=mat, neighbors=8, choice='mean', nonnegative=True)\n",
    "label_image, regions = get_label_image(cor_map, min_pixels=50)\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "label_image, regions = refine_segmentation(submats, regions, label_image)\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_label = 1\n",
    "submat = submats[sel_label-1]\n",
    "region = regions[sel_label-1]\n",
    "minr, minc, maxr, maxc = region.bbox\n",
    "trace = traces[sel_label-1]\n",
    "imshow(submat.mean(0))\n",
    "k = 8\n",
    "plt.plot(trace[700*k:700*(k+1)].cpu(), '-.')\n",
    "trace2 = denoise_trace(trace[700*k:700*(k+1)])\n",
    "plt.plot(trace2.cpu(), '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = submat.reshape(submat.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, V, n_iter = non_negative_factorization(R, init=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model_nmf = NMF(n_components=5, init='random', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model_nmf.fit_transform((R-R.min()).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model_nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "for i in range(5):\n",
    "    imshow(H[i].reshape(submat.shape[1:]))\n",
    "    plt.plot(W[700*k:700*(k+1), i], '-.')\n",
    "    trace2 = denoise_trace(torch.from_numpy(W[700*k:700*(k+1), i]).float().to(device))\n",
    "    plt.plot(trace2.cpu(), '-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(R - torch.mm(U,V)) / torch.norm(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = cor_map[minr:maxr, minc:maxc]\n",
    "label_sub_img = label_image[minr:maxr, minc:maxc]\n",
    "high_threshold = cor[(label_sub_img == sel_label).tolist()].median()\n",
    "low_threshold = cor[(label_sub_img == 0).tolist()].median()\n",
    "target = cor.new_zeros(cor.shape)\n",
    "target[cor > high_threshold] = 1\n",
    "mask = ((cor > high_threshold) | (cor < low_threshold)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(cor.reshape(-1).sort()[0].cpu(), n_bins=100)\n",
    "plt.axvline(x=threshold_otsu(cor.cpu().numpy()))\n",
    "plt.axvline(x=low_threshold.cpu().numpy())\n",
    "plt.axvline(x=high_threshold.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)\n",
    "plt.figure(figsize=(20, 20))\n",
    "for j, trace in enumerate(traces):\n",
    "    k = 8\n",
    "    trace = trace[700*k:700*(k+1)]\n",
    "    trace2 = denoise_trace(trace)\n",
    "    plt.plot(trace.cpu() - j*200, '-.', c=colors[j], label=j+1)\n",
    "    plt.plot(trace2.cpu() - j*200, '-', c=colors[j], label=j+1)\n",
    "plt.legend()\n",
    "plt.title(exp_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = neighbor_cor(mat=mat, neighbors=8, choice='mean', nonnegative=True)\n",
    "label_image, regions = get_label_image(cor_map, min_pixels=50)\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "label_image, regions = refine_segmentation(submats, regions, label_image, min_pixels=50)\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)\n",
    "plt.figure(figsize=(20, 20))\n",
    "for j, trace in enumerate(traces):\n",
    "    k = 8\n",
    "    trace = trace[700*k:700*(k+1)]\n",
    "    trace2 = denoise_trace(trace)\n",
    "    plt.plot(trace.cpu() + j*200, '-.', c=colors[j], label=j+1)\n",
    "    plt.plot(trace2.cpu() + j*200, '-', c=colors[j], label=j+1)\n",
    "plt.legend()\n",
    "plt.title(exp_id)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1, num_classes=1, out_channels=[8, 16, 32], num_conv=2, \n",
    "             n_dim=1, kernel_size=3).to(device)\n",
    "filepath = 'checkpoints/denoise_trace.pt'\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "for i in range(len(all_traces)):\n",
    "    plot_image_label_overlay(cor_maps[i], label_image=all_images[i], title=all_exp_ids[i])\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for j, trace in enumerate(all_traces[i]):\n",
    "        k = 8\n",
    "        trace = trace[700*k:700*(k+1)]\n",
    "        trace2 = denoise_trace(torch.from_numpy(trace).to(device))\n",
    "        plt.plot(trace + j*200, '-.', c=colors[j], label=j+1)\n",
    "        plt.plot(trace2.cpu() + j*200, '-', c=colors[j], label=j+1)\n",
    "    plt.legend()\n",
    "    plt.title(all_exp_ids[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = sorted(meta_data)[np.random.choice(len(meta_data))]\n",
    "print(exp_id)\n",
    "mat = load_mat(exp_id, meta_data, folder, device=device)\n",
    "# the first frame of 7500 frames is missing; skip the initial 50 frames\n",
    "mat_list = [mat[799+750*i:1499+750*i] for i in range(9)]\n",
    "train_idx = list(range(200)) + list(range(550, 700))\n",
    "mat_adj = [detrend_linear(mat=m, train_idx=train_idx) for m in mat_list]\n",
    "mat = torch.cat(mat_adj, dim=0)\n",
    "del mat_adj, mat_list\n",
    "torch.cuda.empty_cache()\n",
    "cor_map = neighbor_cor(mat=mat, neighbors=8, choice='mean', nonnegative=True)\n",
    "label_image, regions = get_label_image(cor_map, min_pixels=50)\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)\n",
    "label_image, regions = refine_segmentation(submats, regions, label_image)\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions, percentile=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 6\n",
    "submats, traces, soft_attention, label_image, regions = refine_one_label(submats[label_idx-1], min_pixels=10, return_traces=True)\n",
    "imshow(soft_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 1\n",
    "trace = traces[label_idx-1]\n",
    "pred = denoise_trace(trace)\n",
    "plot_image_label_overlay(soft_attention, label_image, regions=regions, sel_idx=label_idx-1)\n",
    "zoom_in(pred, seq2=trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(traces)\n",
    "for label_idx in range(1, num_labels+1):\n",
    "    submat = submats[label_idx-1]\n",
    "    trace = traces[label_idx-1]\n",
    "    pred = denoise_trace(trace)\n",
    "    plot_image_label_overlay(cor_map, label_image, regions=regions, sel_idx=label_idx-1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(trace.cpu(), linestyle='--', linewidth=1, color='k', markersize=2, alpha=0.5, label='raw trace')\n",
    "    plt.plot(pred.detach().cpu(), '-', color='b', alpha=1, label='denoised')\n",
    "    plt.legend()\n",
    "    plt.title(label_idx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Low magnification cultured neurons  \n",
    "if dataset_name == 'low_mag_cultured_neurons_2015-12-18':\n",
    "    folder = '/home/tma/projects/optical_profiling/data'\n",
    "    with open(os.path.join(folder, 'meta_data.pkl'), 'rb') as f:\n",
    "        meta_data = pickle.load(f)\n",
    "        exp_id_dict = {s[:10]:s for s in sorted(meta_data)}\n",
    "#     with open(os.path.join(folder, 'videos.pkl'), 'rb') as f:\n",
    "#         videos = pickle.load(f)\n",
    "    if random_file:\n",
    "        exp_id = sorted(meta_data)[np.random.choice(len(meta_data))]\n",
    "    # exp_id = 'D1_FOV3_W2_at135105'\n",
    "    # exp_id = 'F1_FOV3_W1_at143440'\n",
    "    # exp_id = 'D1_FOV3_W1_at135000'\n",
    "    # exp_id = 'D1_FOV2_W2_at134631'\n",
    "    # exp_id = 'E3_FOV2_W2_at155722'\n",
    "    # exp_id = 'E3_FOV2_W1_at155622'\n",
    "    period = 750\n",
    "    signal_start = 250\n",
    "    signal_end = 500\n",
    "    shift = -1\n",
    "    num_segments = 10\n",
    "    skip_segments = 1\n",
    "    trim_size_left = 75\n",
    "    trim_size_right = 25\n",
    "    train_left_skip = 0 # skip from right\n",
    "    train_right_skip = 75 # skip from left\n",
    "    \n",
    "#     # PCA/ICA result from Sami\n",
    "#     mat = loadmat(f'{folder}/D1_FOV3_W2_at135105_segmentation.mat')\n",
    "#     W = mat['sourceImage_out'].reshape(-1, 512, 180)\n",
    "#     H = mat['trace_out']\n",
    "#     for i in range(42):\n",
    "#         imshow(W[i].T)\n",
    "#         plt.figure(figsize=figsize)\n",
    "#         plt.plot(H[:, i])\n",
    "#         plt.title(i)\n",
    "#         plt.show()\n",
    "\n",
    "if dataset_name == 'pooled_ipsc_2018-09-17':\n",
    "    root = '/home/tma/tma-disk/sami/2018-09-17'\n",
    "    use_worldstar_only = True\n",
    "    folders = [s for s in os.listdir(root) if os.path.isdir(f'{root}/{s}') and s not in ['AnalysisCodeExternal', \n",
    "                                                                                         'Coke can movies']]\n",
    "    if use_worldstar_only:\n",
    "        folders = [f for f in folders if re.search('worldstar$', f)]\n",
    "    if random_file:\n",
    "        folder = folders[np.random.choice(len(folders))]\n",
    "#     folder = '164231_FOV3_DIV14_MOI10_FOV7_200ms_2OD_v2_worldstar'\n",
    "    folder = '165201_FOV3_DIV14_MOI5_FOV2_200ms_2OD_v3_worldstar'\n",
    "    print(folder)\n",
    "    nrow, ncol = 180, 300\n",
    "    size = [-1, nrow, ncol]\n",
    "    filepath = f'{root}/{folder}/movie.bin'\n",
    "    mat = load_file(filepath, size)\n",
    "    L = mat.size(0)\n",
    "    if plot:\n",
    "#         daq = np.loadtxt(f'{root}/{folder}/movie_DAQ.txt', skiprows=1)\n",
    "#         x = loadmat(os.path.join(root, 'MOI10_img.mat'))['MOI10_imgs']\n",
    "#         y = loadmat(os.path.join(root, 'MOI10_traces.mat'))['MOI10_traces']\n",
    "#         for i in range(x.shape[2]):\n",
    "#             imshow(x[:,:,i], cmap='binary')\n",
    "#             plt.figure(figsize=(20, 10))\n",
    "#             plt.plot(y[:, i], 'o--', linewidth=1, markersize=2)\n",
    "#             plt.title(i)\n",
    "#             plt.show()\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(mat.mean(-1).mean(-1).cpu())\n",
    "        plt.show()\n",
    "        extract_super_pixels(mat_adj=None, test_left=None, test_right=None, mat_cat=mat, plot=True)\n",
    "    period = 500\n",
    "    signal_start = 0\n",
    "    signal_end = 100\n",
    "    shift = 0\n",
    "    trim_size_left = 0\n",
    "    trim_size_right = 0\n",
    "    num_segments = L // period\n",
    "    skip_segments = 1\n",
    "    train_left_skip = 0 # skip from right\n",
    "    train_right_skip = 50 # skip from left\n",
    "\n",
    "if dataset_name in ['pooled_ipsc_2018-12-07', 'low_mag_beta_cell']:\n",
    "    remove_outliers = True\n",
    "    if dataset_name == 'pooled_ipsc_2018-12-07':\n",
    "        root = '/home/tma/tma-disk/sami/pooled_ipsc_2018-12-07'\n",
    "    if dataset_name == 'low_mag_beta_cell':\n",
    "        root = '/home/tma/tma-disk/sami/2018-12-21 Beta cells'    \n",
    "    filenames = [f[:-4] for f in os.listdir(root) if re.search('.bin$', f)]\n",
    "    if plot and len(filenames) < 10:\n",
    "        for filename in filenames:\n",
    "            size = get_size_from_txt(f'{root}/{filename}.txt')\n",
    "            mat = load_file(f'{root}/{filename}.bin', size=size)\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.plot(mat.mean(-1).mean(-1).cpu())\n",
    "            plt.title(f'{filename}: {size}')\n",
    "            plt.show()\n",
    "            extract_super_pixels(mat_adj=None, test_left=None, test_right=None, mat_cat=mat, plot=True)\n",
    "    filename = 'D2_NoBlue_highG_3p5V_max_FOV4_at154522' if dataset_name=='low_mag_beta_cell' else filenames[0]\n",
    "    if random_file:\n",
    "        filename = filenames[np.random.choice(len(filenames))]\n",
    "        print(filename)\n",
    "    size = get_size_from_txt(f'{root}/{filename}.txt')\n",
    "    mat = load_file(f'{root}/{filename}.bin', size=size)\n",
    "    if remove_outliers:\n",
    "        frame_mean = mat.mean(-1).mean(-1).cpu()\n",
    "        mask = detect_outliers(frame_mean)\n",
    "        mat = mat[mask]\n",
    "        if np.sum(mask) < len(mat):\n",
    "            print(f'Removed {len(mat) - np.sum(mask)} outlier frames')  \n",
    "\n",
    "if dataset_name == 'high_mag_adrenal_cortex':\n",
    "    folder = '/home/tma/tma-disk/sami/Adrenal Cortex'\n",
    "    filepath = f'{folder}/floxopatch_glomerulous_20hz.tif'\n",
    "    im = Image.open(filepath)\n",
    "    array = np.array([np.array(page) for page in ImageSequence.Iterator(im)])\n",
    "    mat = torch.from_numpy(array.astype('float32')).to(device)\n",
    "    if plot:\n",
    "        plt.plot(mat.mean(-1).mean(-1).cpu())\n",
    "        plt.show()\n",
    "        extract_super_pixels(mat_adj=None, test_left=None, test_right=None, mat_cat=mat, plot=True)\n",
    "        res = loadmat(f'{folder}/pca_ica_out.mat')\n",
    "        A = res['out'] \n",
    "        C = res['vica']\n",
    "        for i in range(A.shape[-1]):\n",
    "            imshow(A[:, :, i])\n",
    "            plt.plot(C[:, i])\n",
    "            plt.title(i)\n",
    "            plt.show()\n",
    "\n",
    "if dataset_name == 'high_mag_beta_cell':\n",
    "    root = '/home/tma/tma-disk/sami/2018-09-21 DRH347 test on screening rig'\n",
    "    folders = [s for s in os.listdir(root) if os.path.isdir(f'{root}/{s}') and s != 'AnalysisCodeExternal']\n",
    "    folder = folders[0]\n",
    "    if random_file:\n",
    "        folder = folders[np.random.choice(len(folders))]\n",
    "    print(folder)\n",
    "    nrow, ncol = 90, 150\n",
    "    size = [-1, nrow, ncol]\n",
    "    filepath = f'{root}/{folder}/movie.bin'\n",
    "    mat = load_file(filepath, size)\n",
    "    L = mat.size(0)\n",
    "    frame_mean = mat.mean(-1).mean(-1)\n",
    "    sel_idx = detect_outliers(frame_mean, whis=5, return_outliers=False)\n",
    "    if np.sum(sel_idx) < L:\n",
    "        print(f'Detect {L - np.sum(sel_idx)} outliers and remove these {L - np.sum(sel_idx)} '\n",
    "              'frames from downstream analysis')\n",
    "        mat = mat[sel_idx]\n",
    "    if plot:\n",
    "    #     daq = np.loadtxt(f'{root}/{folder}/movie_DAQ.txt', skiprows=1)\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(mat.mean(-1).mean(-1).cpu())\n",
    "        plt.show()\n",
    "        extract_super_pixels(mat_adj=None, test_left=None, test_right=None, mat_cat=mat, plot=True)\n",
    "        \n",
    "if dataset_name in ['low_mag_cultured_neurons_2015-12-18', 'pooled_ipsc_2018-09-17']:\n",
    "    signal_length = signal_end - signal_start\n",
    "    left0 = trim_size_left + shift\n",
    "    right0 = period - trim_size_right + shift\n",
    "    left1 = signal_start + shift\n",
    "    right1 = signal_end + shift\n",
    "    train_size_left = left1 - left0 - train_left_skip\n",
    "    train_size_right = right0 - right1 - train_right_skip\n",
    "    seg_idx = range(skip_segments, num_segments)\n",
    "    num_seg = num_segments - skip_segments\n",
    "    start0 = [period*i + left0 for i in seg_idx]\n",
    "    end0 = [period*i + right0 for i in seg_idx]\n",
    "    start1 = [period*i + left1 for i in seg_idx]\n",
    "    end1 = [period*i + right1 for i in seg_idx]\n",
    "    length0 = right0 - left0\n",
    "    length1 = right1 - left1\n",
    "    test_left = left1 - left0\n",
    "    test_right = right1 - left0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "pred = denoise_trace(torch.from_numpy(C[:, i]).float().to(device))\n",
    "zoom_in(seq=pred, seq2=C[:, i], batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(mat, denoise=0, num_neighbors=4, cor_choice='mean', connectivity=1, use_detrend=True, weight_percentile=50, \n",
    "                 low_magnification=True, use_mean_image=False):\n",
    "    if low_magnification:\n",
    "        mat_adj = detrend(mat, start0, end0, train_size_left, train_size_right, linear_order=3, use_mean_bg=False, plot=plot, \n",
    "                          test_left=test_left, test_right=test_right, device=device, exp_id=exp_id, meta_data=meta_data, \n",
    "                          folder=folder, show_singular_values=False)\n",
    "        cor_global, label_image, regions = extract_super_pixels(mat_adj=mat_adj, test_left=test_left, test_right=test_right, \n",
    "                                                        num_neighbors=num_neighbors, cor_choice=cor_choice, connectivity=None, \n",
    "                                                        plot=plot, use_mean_image=use_mean_image)\n",
    "        mat_adj = torch.cat(mat_adj)\n",
    "    else:\n",
    "        L = mat.size(0)\n",
    "        num_segments = L // period\n",
    "        mat_adj = detrend_high_magnification(mat, skip_segments=skip_segments, num_segments=num_segments, period=period, \n",
    "                                             train_size_left=train_size_left, train_size_right=train_size_right, \n",
    "                                             linear_order=3, plot=False, signal_start=signal_start, signal_end=signal_end, \n",
    "                                             filepath=None, size=None, device=torch.device('cuda'), start0=None, end0=None, \n",
    "                                             return_mat=False)\n",
    "        cor_global, label_image, regions = extract_super_pixels(mat_cat=mat_adj, mat_adj=None, test_left=None, test_right=None, \n",
    "                                                                num_neighbors=num_neighbors, cor_choice=cor_choice, \n",
    "                                                                connectivity=None, \n",
    "                                                                plot=plot, use_mean_image=use_mean_image)\n",
    "    nframe, nrow, ncol = mat_adj.shape\n",
    "    if denoise == 1:\n",
    "        size = (nrow, ncol)\n",
    "        spatial_threshold = get_threshold(size, loss_fn=total_variation)\n",
    "        temporal_threshold = get_threshold(nframe, loss_fn=second_order_difference)\n",
    "        U, V = pmd_compress(mat_adj.reshape(nframe, -1).T, size, max_num_fails=5, max_num_components=10, tol=1e-1, \n",
    "                    spatial_threshold=spatial_threshold, temporal_threshold=temporal_threshold, \n",
    "                    verbose=False)\n",
    "        mat_adj = torch.mm(U, V).T.reshape(nframe, nrow, ncol)\n",
    "    elif denoise == 2:\n",
    "        A, B, loss_history = step_decompose(mat_adj.reshape(nframe, -1), num_components=10, verbose=False)\n",
    "        mat_adj = torch.mm(A, B).reshape(mat_adj.shape)\n",
    "    traces, submats = get_submat_traces(seg_idx=0, regions=regions, label_image=label_image, \n",
    "                            mat_adj=[mat_adj if use_detrend else torch.cat([mat[s:e] for s, e in zip(start0, end0)])], \n",
    "                            weight_percentile=weight_percentile, sig_list=None, mat_list=None, cor=cor_global, \n",
    "                            weighted_denominator=True, return_name='mat_adj', compare=False, test_left=test_left, \n",
    "                            test_right=test_right)\n",
    "    return cor_global, label_image, regions, traces, submats\n",
    "\n",
    "\n",
    "def zoom_in_trace(trace, markers='-', trace2=None, figsize=(20, 10), alpha1=1, alpha2=0.5):\n",
    "    if isinstance(trace, torch.Tensor):\n",
    "        trace = trace.squeeze().detach().cpu()\n",
    "#     if 'test_left' not in globals():\n",
    "#         num_seg = 10\n",
    "#         length0 = int(math.ceil(len(trace) / num_seg))\n",
    "#         test_left = 0\n",
    "#         test_right = length0\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(trace, markers, linewidth=1, color='b', markersize=2, label='trace 1')\n",
    "    if trace2 is not None:\n",
    "        if isinstance(trace2, torch.Tensor):\n",
    "            trace2 = trace2.squeeze().detach().cpu()\n",
    "        plt.plot(trace2, markers, linewidth=1, color='r', markersize=2, label='trace 2', alpha=0.5)\n",
    "        plt.legend()\n",
    "    for i in range(num_seg):\n",
    "        plt.axvline(test_left+length0*i, linestyle='--', linewidth=1, color='g')\n",
    "        plt.axvline(test_right+length0*i, linestyle='--', linewidth=1, color='g')\n",
    "#         plt.axvline(train_size_left+length0*i, linestyle='-.', linewidth=1, color='r')\n",
    "#         plt.axvline(length0-train_size_right+length0*i, linestyle='-.', linewidth=1, color='r')\n",
    "    plt.title(f'Label {label_idx}')\n",
    "    plt.show()\n",
    "    for i in range(num_seg):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(trace[length0*i:length0*(i+1)].cpu(), markers, linewidth=1, color='b', markersize=2, label='trace 1', alpha=alpha1)\n",
    "        if trace2 is not None:\n",
    "            plt.plot(trace2[length0*i:length0*(i+1)].cpu(), markers, linewidth=1, color='r', markersize=2, label='trace 2', \n",
    "                     alpha=alpha2)\n",
    "            plt.legend()\n",
    "        plt.axvline(test_left, linestyle='--', linewidth=1, color='g')\n",
    "        plt.axvline(test_right, linestyle='--', linewidth=1, color='g')\n",
    "#         plt.axvline(train_size_left, linestyle='-.', linewidth=1, color='r')\n",
    "#         plt.axvline(length0-train_size_right, linestyle='-.', linewidth=1, color='r')   \n",
    "        plt.title(f'Segment {i+1}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = exp_id_dict['D2_FOV2_W1']\n",
    "# exp_id = exp_id_dict['D1_FOV3_W1']\n",
    "# exp_id = exp_id_dict['F1_FOV3_W1']\n",
    "# exp_id = exp_id_dict['D1_FOV1_W1']\n",
    "# exp_id = sorted(meta_data)[10]\n",
    "# exp_id = sorted(meta_data)[np.random.choice(len(meta_data))]\n",
    "print(exp_id)\n",
    "start_time = time.time()\n",
    "mat = load_mat(exp_id, meta_data, folder)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_adj = detrend(mat, start0, end0, train_size_left, train_size_right, linear_order=3, use_mean_bg=False, plot=False, \n",
    "                  test_left=test_left, test_right=test_right, device=device, show_singular_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_adj = detrend_high_magnification(mat, skip_segments=skip_segments, num_segments=num_segments, period=period, \n",
    "                                     train_size_left=train_size_left, train_size_right=train_size_right, \n",
    "                                     linear_order=3, plot=False, signal_start=signal_start, signal_end=signal_end, \n",
    "                                     filepath=None, size=None, device=torch.device('cuda'), start0=None, end0=None, \n",
    "                                     return_mat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_adj, trend = detrend_linear(mat, return_trend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mat.mean(-1).mean(-1).cpu(), 'r-')\n",
    "plt.plot(trend.mean(-1).mean(-1).cpu(), 'b--')\n",
    "plt.show()\n",
    "plt.plot(mat_adj.mean(-1).mean(-1).cpu(), 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cor_global, label_image, regions, traces, submats = run_pipeline(mat, num_neighbors=8, cor_choice='mean', connectivity=None, \n",
    "                                                                 use_detrend=True, weight_percentile=50, use_mean_image=False)\n",
    "print(time.time() - start_time)\n",
    "plot_image_label_overlay(cor_global, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cor_global, label_image, regions, traces, submats = run_pipeline(mat, num_neighbors=4, cor_choice='mean', connectivity=1, \n",
    "                                                                 use_detrend=True, weight_percentile=50, low_magnification=False, \n",
    "                                                                 use_mean_image=False)\n",
    "print(f'Time spent: {time.time() - start_time}')\n",
    "plot_image_label_overlay(cor_global, label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(traces)\n",
    "for label_idx in range(1, num_labels+1):\n",
    "    submat, label_mask, weight = submats[label_idx-1]\n",
    "    trace = traces[label_idx-1]\n",
    "    plot_image_label_overlay(cor_global, label_image, sel_idx=label_idx-1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(trace.cpu(), linestyle='-', linewidth=1, color='b', markersize=2, alpha=1, label='raw trace')\n",
    "#     plt.plot(pred.detach().cpu(), '-', color='r', alpha=0.5, label='denoised')\n",
    "#     plt.legend()\n",
    "    plt.title(label_idx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 2\n",
    "submat, label_mask, weight = submats[label_idx-1]\n",
    "trace = traces[label_idx-1]\n",
    "trace_clean = denoise_trace(trace)\n",
    "plot_image_label_overlay(cor_global, label_image, sel_idx=label_idx-1)\n",
    "# zoom_in_trace(trace, markers='-', figsize=(20, 15))\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.plot(trace.cpu(), 'k--', alpha=0.5, label='raw')\n",
    "plt.plot(trace_clean.detach().cpu(), 'b-', label='denoised')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "for i in range(9):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.plot(trace[650*i:650*i+650].cpu(), 'k-', alpha=0.5, label='raw')\n",
    "    plt.plot(trace_clean[650*i:650*i+650].detach().cpu(), 'b-', label='denoised')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_pos(mat, k=3):\n",
    "    if isinstance(mat, np.ndarray):\n",
    "        topk = np.argsort(-mat.reshape(-1))[:k]\n",
    "    elif isinstance(mat, torch.Tensor):\n",
    "        topk = mat.reshape(-1).topk(k)[1]\n",
    "        topk = topk.detach().cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(f'Only handle np.ndarray and torch.Tensor, but mat is of type {type(mat)}')\n",
    "    shape = mat.shape\n",
    "    return np.array(np.unravel_index(topk, shape)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 5\n",
    "# sel_idx = slice(650*i, 650*(i+1))\n",
    "sel_idx = slice(len(submat))\n",
    "plt.figure(figsize=figsize)\n",
    "sel_pos = topk_pos(submat.mean(0), k=20)\n",
    "for pos in sel_pos[[0, 1]]:\n",
    "    trace = submat[sel_idx, pos[0], pos[1]]\n",
    "    plt.plot(trace.detach().cpu(), label=f'{pos}', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 5\n",
    "# sel_idx = slice(650*i, 650*(i+1))\n",
    "plt.figure(figsize=figsize)\n",
    "for pos in sel_pos[[0, 1]]: #[[10, 13], [12, 16]]:\n",
    "    trace = submat[sel_idx, pos[0], pos[1]]\n",
    "    mean = trace.mean()\n",
    "    std = trace.std()\n",
    "    pred = model((trace-mean)/std)\n",
    "    pred = model(pred)\n",
    "    pred = pred * std + mean\n",
    "    plt.plot(pred.detach().cpu(), label='denoised', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1, num_classes=1, out_channels=[4, 8, 16], num_conv=2, n_dim=3, \n",
    "             kernel_size=[3, 3, 3], same_shape=True).to(device)\n",
    "model.load_state_dict(torch.load('checkpoints/3d_denoise.pt'))\n",
    "\n",
    "with torch.no_grad():\n",
    "    submat_clean = model(submat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(submat.mean(0))\n",
    "imshow(submat_clean.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(submat[3000:4000, 15, 31].detach().cpu(), alpha=0.5)\n",
    "plt.show()\n",
    "plt.plot(submat_clean[3000:4000, 15, 31].detach().cpu(), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1, num_classes=1, out_channels=[4, 8, 16], num_conv=2, n_dim=3, kernel_size=[3, 3, 3], \n",
    "             same_shape=True).to(device)\n",
    "\n",
    "filepath = 'checkpoints/segmentation_count_hardmask.pt'\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(submat_clean).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_global, label_image, regions = extract_super_pixels(mat_adj=None, test_left=None, test_right=None, mat_cat=submat_clean, \n",
    "                                                        num_neighbors=4, cor_choice='mean', connectivity=None, \n",
    "                                                        min_pixels=10, image=pred, plot=True, use_mean_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces, submats = get_submat_traces(seg_idx=0, regions=regions, label_image=label_image, \n",
    "                        mat_adj=[submat_clean], \n",
    "                        weight_percentile=50, sig_list=None, mat_list=None, cor=cor_global, weighted_denominator=True, \n",
    "                        return_name='mat_adj', compare=False, test_left=None, test_right=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(traces)\n",
    "for label_idx in range(1, num_labels+1):\n",
    "    submat, label_mask, weight = submats[label_idx-1]\n",
    "    trace = traces[label_idx-1]\n",
    "    plot_image_label_overlay(cor_global, label_image, sel_idx=label_idx-1)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(trace.cpu(), linestyle='-', linewidth=1, color='b', markersize=2, alpha=1, label='raw trace')\n",
    "#     plt.plot(pred.detach().cpu(), '-', color='r', alpha=0.5, label='denoised')\n",
    "#     plt.legend()\n",
    "    plt.title(label_idx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 1\n",
    "submat, label_mask, weight = submats[label_idx-1]\n",
    "trace = traces[label_idx-1]\n",
    "trace_clean = denoise_trace(trace)\n",
    "plot_image_label_overlay(cor_global, label_image, sel_idx=label_idx-1)\n",
    "for i in range(9):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.plot(trace[650*i:650*i+650].cpu(), 'k--', alpha=0.5, label='raw')\n",
    "    plt.plot(trace_clean[650*i:650*i+650].detach().cpu(), 'b-', label='denoised')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "# zoom_in_trace(trace, markers='-', figsize=(20, 15), trace2=trace_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generated by Trinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/tma/tma-disk/sami/trinh/20190924_155117_FOV9.bin'\n",
    "mat = load_file(filepath, size=(4000, 200, 2000))\n",
    "\n",
    "mat = mat[100:, :, 600:1200]\n",
    "\n",
    "cor_global = neighbor_cor(mat, neighbors=8, plot=True, choice='mean', title='correlation map')\n",
    "\n",
    "cor_global = mat.mean(0) * cor_global\n",
    "cor_global = cor_global / cor_global.max()\n",
    "\n",
    "image = cor_global.detach().cpu().numpy()\n",
    "label_image, regions = get_label_image(image, min_pixels=50, connectivity=1, plot=True)\n",
    "\n",
    "traces, submats = get_submat_traces(seg_idx=0, regions=regions, label_image=label_image, \n",
    "                        mat_adj=[mat], \n",
    "                        weight_percentile=50, sig_list=None, mat_list=None, cor=cor_global, weighted_denominator=True, \n",
    "                        return_name='mat_adj', compare=False)\n",
    "\n",
    "plot_image_label_overlay(image, label_image)\n",
    "\n",
    "from utility import read_tiff_file\n",
    "for f in os.listdir('/home/tma/tma-disk-tmp/trinh'):\n",
    "    if re.search('.tif', f):\n",
    "        tiff = read_tiff_file(f'/home/tma/tma-disk-tmp/trinh/{f}')\n",
    "        imshow(tiff.T, title=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
