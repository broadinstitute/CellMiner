{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, functools, itertools, collections, time, random, pickle, warnings, json, subprocess\n",
    "pkg_path = '/home/jupyter/code'\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas\n",
    "from skimage.color import label2rgb\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utility import get_label_image, get_cor, get_cor_map, get_topk_indices, get_cor_map_4d, get_local_mean\n",
    "from utility import get_prime_factors, get_local_median, scale_and_shift, adaptive_avg_pool\n",
    "from utility import mark_points_in_intervals\n",
    "from visualization import imshow, plot_image_label_overlay, make_video_ffmpeg, get_good_colors, plot_colortable, save_gif_file\n",
    "from models import UNet\n",
    "from denoise import get_denoised_mat, model_denoise, SeparateNet\n",
    "from segmentation import get_traces, semi_supervised_segmentation\n",
    "from optical_electrophysiology import extract_traces\n",
    "\n",
    "use_gpu = True\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', '-m', 'cp', 'gs://broad-opp-voltage/sami_2015/processed/E3_FOV1_W1_at155339/mat.npy', 'mat.npy']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', '-m', 'cp', \n",
    "           'gs://broad-opp-voltage/sami_2015/processed/E3_FOV1_W1_at155339/noise2self/denoised_movie_frame0to6500_step69000.npy', \n",
    "           'denoised_mat.npy']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cosine_similarity(x, y=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (n_x, dim)\n",
    "        y: (n_y, dim)\n",
    "    \n",
    "    Returns:\n",
    "        cos: (n_x, n_y)\n",
    "    \"\"\"\n",
    "    if y is None:\n",
    "        y = x\n",
    "    x = x - x.mean(1, keepdim=True)\n",
    "    y = y - y.mean(1, keepdim=True)\n",
    "    cos = torch.mm(x, y.T) / x.norm(dim=1, keepdim=True) / y.norm(dim=1)\n",
    "    return cos\n",
    "\n",
    "def manhattan_distance(coords):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        coords: (n_pts, ndim)\n",
    "    \"\"\"\n",
    "    return (coords.unsqueeze(2) - coords.T).abs().sum(1)\n",
    "\n",
    "def graph_laplacian(weight, normalized=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        weight: non-negative symmetric 2D matrix\n",
    "       \n",
    "    Returns:\n",
    "        L: \n",
    "        \n",
    "    \"\"\"\n",
    "    assert weight.ndim==2 and weight.min() >= 0\n",
    "    diagonal = weight.sum(1)\n",
    "    L = torch.diag(diagonal) - weight\n",
    "    if normalized and diagonal.min() > 0:\n",
    "        d = 1./torch.sqrt(diagonal)\n",
    "        L = d.unsqueeze(0) * L * d.unsqueeze(1)\n",
    "    return L\n",
    "\n",
    "def pairwise_dist(x, y=None, sqrt=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (n_pts, ndim)\n",
    "        y: if None, set to be x\n",
    "        \n",
    "    \"\"\"\n",
    "    if y is None:\n",
    "        y = x\n",
    "    dist = (x*x).sum(1, keepdim=True) + (y*y).sum(1) - 2*torch.mm(x, y.T)\n",
    "    dist[dist<0] = 0\n",
    "    if sqrt:\n",
    "        return torch.sqrt(dist)\n",
    "    else:\n",
    "        return dist\n",
    "\n",
    "def k_means(points, n_clusters, random_init=False, return_centers=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        points: (n_pts, ndim)\n",
    "    \n",
    "    Returns:\n",
    "        if return_centers is True:\n",
    "            indices: (n_pts, ), LongTensor, labels\n",
    "            values: (n_pts, ), distance to center\n",
    "            centers: (n_clusters, ndim)\n",
    "        \n",
    "    Examples:\n",
    "        good_colors = get_good_colors()\n",
    "        points = torch.randn((100, 2))\n",
    "        indices, values, centers = k_means(points, n_clusters=10, return_centers=True)\n",
    "        fig, ax = plt.subplots(figsize=(20, 20))\n",
    "        ax.scatter(points[:, 0].cpu().numpy(), points[:, 1].cpu().numpy(), c=[good_colors[i.item()] for i in indices], marker='o')\n",
    "        ax.scatter(centers[:, 0].cpu(), centers[:, 1].cpu(), c=good_colors[:10], marker='v', s=50)\n",
    "        plt.show()\n",
    "    \"\"\"\n",
    "    n_pts, ndim = points.shape\n",
    "    if random_init:\n",
    "        centers = points[torch.randperm(n_pts)[:n_clusters]]\n",
    "    else:\n",
    "        sel_idx = np.random.choice(n_pts)\n",
    "        centers = points[sel_idx].unsqueeze(0)\n",
    "        for _ in range(n_clusters-1):\n",
    "            dist = pairwise_dist(centers, points).min(dim=0)[0]\n",
    "            sel_idx = torch.multinomial(dist, 1)\n",
    "            centers = torch.cat([centers, points[sel_idx]], dim=0)\n",
    "    labels = torch.zeros(n_pts).long().to(points.device)\n",
    "    indices = torch.ones(n_pts).long().to(points.device)\n",
    "    while not torch.equal(labels, indices):\n",
    "        labels = indices\n",
    "        dist = pairwise_dist(centers, points)\n",
    "        values, indices = dist.min(dim=0) #ToDo: check empty clusters\n",
    "        centers = torch.stack([points[indices==i].mean(0) for i in range(n_clusters)], dim=0)\n",
    "    if return_centers:\n",
    "        return indices, values, centers\n",
    "    else:\n",
    "        return indices, values.sum()\n",
    "\n",
    "def split_clusters(sel_label_idx, mat, label_image, cor_threshold=0.8, min_num_pixels=50, max_num_pixels=1200, max_dist=2, \n",
    "                   median_detrend=True, apply_fft=True, fft_max_freq=200, verbose=True, plot=False, soma_coords=None):\n",
    "    def show_plot():\n",
    "        image = torch.zeros_like(cor)\n",
    "        image[coords[:, 0], coords[:, 1]] = image.new_tensor(labels+1)\n",
    "        minr, minc = coords.min(dim=0)[0]\n",
    "        maxr, maxc = coords.max(dim=0)[0]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image[minr:maxr, minc:maxc].cpu().numpy())\n",
    "        ax.set_title(f'')\n",
    "        for i, (x, y) in enumerate(soma_coords):\n",
    "            if x >= minr and x < maxr and y >= minc and y < maxr:\n",
    "                ax.scatter([(x-minr).item()], [(y-minc).item()], s=30, c='r')\n",
    "                ax.text((x-minr).item()+1, (y-minc).item(), i+1, color='r', fontweight='bold')\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    coords = torch.stack(torch.nonzero(label_image==sel_label_idx, as_tuple=True), dim=1)\n",
    "    if len(coords) <= min_num_pixels:\n",
    "        return\n",
    "    m = mat[:, coords[:, 0], coords[:, 1]]\n",
    "\n",
    "    dist = manhattan_distance(coords)\n",
    "    dist.fill_diagonal_(max_dist + 1)\n",
    "    adj_mat = (dist <= max_dist)\n",
    "\n",
    "    if median_detrend:\n",
    "        m = m - get_local_median(m, window_size=50, dim=0)\n",
    "    if apply_fft:\n",
    "        fft = torch.rfft(m.T, signal_ndim=1, normalized=True)[..., :fft_max_freq, :].reshape(m.size(1), -1)\n",
    "    else:\n",
    "        fft = m\n",
    "    fft = fft - fft.mean(1, keepdim=True)\n",
    "    norm = torch.norm(fft, dim=1)\n",
    "    cor = torch.mm(fft, fft.T) / (norm.unsqueeze(1) * norm)\n",
    "    cor[~adj_mat] = 0\n",
    "    cor[cor < 0] = 0\n",
    "\n",
    "    laplacian = graph_laplacian(cor)\n",
    "    eigenvalues, eigenvectors = torch.symeig(laplacian, eigenvectors=True)\n",
    "\n",
    "    k = 2\n",
    "    embedding = eigenvectors[:,:k]\n",
    "    embedding = embedding / torch.norm(embedding, dim=1, keepdim=True)\n",
    "    labels, dist = k_means(embedding, k)\n",
    "    bincount = torch.bincount(labels)\n",
    "    val_cnt, idx_cnt = bincount.sort()\n",
    "    if val_cnt[0] <= min_num_pixels and val_cnt[1] <= max_num_pixels:\n",
    "        if verbose:\n",
    "            print(bincount.tolist())\n",
    "        return\n",
    "    if val_cnt[0] <= min_num_pixels//2 and val_cnt[1] > max_num_pixels:\n",
    "        row_idx, col_idx = coords[labels==idx_cnt[0]].T\n",
    "        label_image[row_idx, col_idx] = 0\n",
    "        if verbose:\n",
    "            print(f'Reset {val_cnt[0]} pixels to background')\n",
    "        return split_clusters(sel_label_idx, mat, label_image, cor_threshold=cor_threshold, min_num_pixels=min_num_pixels, \n",
    "                              max_dist=max_dist, median_detrend=median_detrend, apply_fft=apply_fft, fft_max_freq=fft_max_freq)\n",
    "    x = torch.stack([m[:, labels==i].mean(1) for i in range(2)], dim=0)\n",
    "    if median_detrend:\n",
    "        x = x - get_local_median(x, window_size=50, dim=-1)\n",
    "    if apply_fft:\n",
    "        x = torch.rfft(x, signal_ndim=1, normalized=True)[..., :fft_max_freq, :].reshape(x.size(0), -1)\n",
    "    cor_val = simple_cosine_similarity(x[:1], x[1:]).item()\n",
    "    if verbose:\n",
    "        print(cor_val)\n",
    "    if cor_val > cor_threshold:\n",
    "        if verbose:\n",
    "            print('cor_val > cor_threshold')\n",
    "        return\n",
    "    row_idx, col_idx = coords[labels==idx_cnt[0]].T\n",
    "    label_image[row_idx, col_idx] = label_image.max() + 1\n",
    "    if verbose:\n",
    "        print(f'Split {sel_label_idx} into {sel_label_idx} ({val_cnt[1]}) and {label_image.max().item()} ({val_cnt[0]})')\n",
    "    if plot:\n",
    "        show_plot()\n",
    "    if (labels==idx_cnt[1]).sum() > min_num_pixels:\n",
    "        return split_clusters(sel_label_idx, mat, label_image, cor_threshold=cor_threshold, min_num_pixels=min_num_pixels, \n",
    "                              max_dist=max_dist, median_detrend=median_detrend, apply_fft=apply_fft, fft_max_freq=fft_max_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'optosynth_test_mb'\n",
    "# data_folder = '../data'\n",
    "\n",
    "mat = torch.from_numpy(np.load(f'{data_folder}/mat.npy')).float().to(device)\n",
    "trend = torch.from_numpy(np.load(f'{data_folder}/trend.npy')).float().to(device)\n",
    "clean = torch.from_numpy(np.load(f'{data_folder}/clean.npy')).float().to(device)\n",
    "masks = torch.from_numpy(np.load(f'{data_folder}/masks_nyx.npy')).to(device)\n",
    "soma_coords = torch.from_numpy(np.load(f'{data_folder}/soma_coords_n2.npy')).to(device)\n",
    "true_traces = torch.from_numpy(np.load(f'{data_folder}/neuron_mean_fluorescence_nt.npy')).float().to(device)\n",
    "nframe, nrow, ncol = mat.shape\n",
    "mask_soma = torch.zeros(nrow, ncol).bool()\n",
    "mask_soma[soma_coords[:, 1], soma_coords[:, 0]] = True\n",
    "mask_cell = masks.float().max(0)[0].bool()\n",
    "target = clean - trend\n",
    "\n",
    "del clean, trend\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "save_folder = '2d-noise2self_with_features'\n",
    "filepath = f'{save_folder}/denoised_movie_full_step64000.npy'\n",
    "denoised_mat = torch.from_numpy(np.load(filepath)).float().to(device)\n",
    "# median = get_local_median(denoised_mat, dim=0)\n",
    "# denoised_mat = denoised_mat - median\n",
    "# mat_fft = torch.rfft(denoised_mat.transpose(0, 2), signal_ndim=1).reshape(ncol, nrow, -1).transpose(0, 2)\n",
    "\n",
    "median_detrend = False\n",
    "if median_detrend:\n",
    "    true_traces_median = get_local_median(true_traces, dim=-1)\n",
    "    true_traces -= true_traces_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = 'optosynth_test_mb'\n",
    "# mat = np.load(f'{data_folder}/mat.npy')\n",
    "# masks = np.load(f'{data_folder}/masks_nyx.npy')\n",
    "# true_traces = np.load(f'{data_folder}/neuron_mean_fluorescence_nt.npy')\n",
    "\n",
    "# os.makedirs('funimg_data')\n",
    "# np.save('funimg_data/mat.npy', np.ascontiguousarray(mat.transpose((1,2,0))))\n",
    "# np.save('funimg_data/neuron_masks_nyx.npy', masks)\n",
    "# np.save('funimg_data/neuron_traces_nt.npy', true_traces)\n",
    "\n",
    "# mat_detrended = mat - get_local_median(mat, window_size=50, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = 1\n",
    "nframe_per_seg = 650\n",
    "mat = torch.from_numpy(np.load('mat.npy')[(-nseg*nframe_per_seg):]).to(device)\n",
    "denoised_mat = torch.from_numpy(np.load('denoised_mat.npy')[(-nseg*nframe_per_seg):]).to(device)\n",
    "nframe, nrow, ncol = mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.from_numpy(np.load('trefide_demo.npy')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_map = get_cor_map_4d(mat.reshape(nseg, -1, nrow, ncol))\n",
    "# label_image, regions = get_label_image(cor_map)\n",
    "# label_image = torch.from_numpy(label_image).to(device)\n",
    "# imshow(cor_map)\n",
    "# plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)\n",
    "# submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=regions)\n",
    "# denoised_submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=regions)\n",
    "\n",
    "def basic_segmentation(mat, show=True, median_detrend=False, fft=False, fft_max_freq=100):\n",
    "    if median_detrend:\n",
    "        mat = mat - get_local_median(mat, window_size=50, dim=-3)\n",
    "    if fft:\n",
    "        mat = torch.rfft(mat.transpose(0, 2), signal_ndim=1, normalized=True)[..., :fft_max_freq, :].reshape(\n",
    "            mat.size(2), mat.size(1), -1).transpose(0, 2)\n",
    "    if mat.ndim == 3:\n",
    "        cor_map = get_cor_map(mat)\n",
    "    elif mat.ndim == 4:\n",
    "        cor_map = get_cor_map_4d(mat)\n",
    "    label_image, regions = get_label_image(cor_map)\n",
    "    label_image = torch.from_numpy(label_image).to(mat.device)\n",
    "    if show:\n",
    "        imshow(cor_map)\n",
    "        plot_image_label_overlay(cor_map, label_image=label_image, regions=regions)\n",
    "    return cor_map, label_image, regions\n",
    "\n",
    "median_detrend = False\n",
    "apply_fft = False\n",
    "cor_map, label_image, regions = basic_segmentation(mat, median_detrend=median_detrend, fft=apply_fft, fft_max_freq=200, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=None, median_detrend=median_detrend)\n",
    "denoised_submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=None, \n",
    "                                                   median_detrend=median_detrend)\n",
    "for i in range(len(traces)):\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.set_title(i+1)\n",
    "    ax.plot(traces[i].cpu(), 'r-', alpha=0.5, label='raw')\n",
    "    ax.plot(denoised_traces[i].cpu(), 'g-', alpha=0.5, label='denoised')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_labels = label_image.max().item()\n",
    "# fig, ax = plt.subplots(num_labels, figsize=(20, 10*num_labels))\n",
    "# for i in range(len(traces)):\n",
    "#     ax[i].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[i].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[i].legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# start_time = time.time()\n",
    "# soft_mask, model = semi_supervised_segmentation(mat, cor_map=cor_map, model=None, out_channels=[8,8,8,8], \n",
    "#                                                 kernel_size=3, frames_per_iter=100, num_iters=100, \n",
    "#                                                 print_every=20, select_frames=False, optimizer_fn=torch.optim.AdamW, \n",
    "#                                                 optimizer_fn_args = {'lr': 1e-2, 'weight_decay': 1e-3}, \n",
    "#                                                 save_loss_folder=None, loss_threshold=0, reduction='mean',\n",
    "#                                                 last_out_channels=None,\n",
    "#                                                 return_model=True, verbose=True)\n",
    "# print(time.time() - start_time)\n",
    "\n",
    "# imshow(soft_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft_max_freq = 200\n",
    "# tmp = denoised_traces[:2]\n",
    "# tmp = tmp - get_local_median(tmp, dim=-1)\n",
    "# tmp = torch.rfft(tmp, signal_ndim=1, normalized=True)[..., :fft_max_freq, :].reshape(tmp.size(0), -1)\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.plot(tmp.T.cpu())\n",
    "# plt.title(f'Correlation {simple_cosine_similarity(tmp)[0, 1].item()}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regionprops(label_image.cpu().numpy())\n",
    "box_coords = soma_coords.new_tensor(np.array([region.bbox for region in regions]))[:, [1, 3, 0, 2]]\n",
    "box_coords = box_coords.reshape(box_coords.shape[0], box_coords.shape[1]//2, 2)\n",
    "selected = mark_points_in_intervals(soma_coords, box_coords)\n",
    "false_negatives = [i+1 for i in torch.nonzero(selected.sum(1) == 0, as_tuple=True)[0].tolist()]\n",
    "false_positives = [i+1 for i in torch.nonzero(selected.sum(0) == 0, as_tuple=True)[0].tolist()]\n",
    "print('False Negatives (missed {} neurons): {}'.format(len(false_negatives), false_negatives))\n",
    "print('False Positives ({} empty boxes): {}'.format(len(false_positives), false_positives))\n",
    "good_box_idx = torch.nonzero(selected.sum(0)==1, as_tuple=True)[0]\n",
    "soma_idx = torch.nonzero(selected[:, good_box_idx].T, as_tuple=True)[1]\n",
    "print('{} good boxes: {}'.format(len(good_box_idx), [(i+1, j+1) for i, j in zip(good_box_idx.tolist(), soma_idx.tolist())]))\n",
    "\n",
    "figsize = (20, 10)\n",
    "sel_idx = None\n",
    "image_label_overlay = label2rgb(label_image.cpu().numpy(), image=cor_map.cpu().numpy())\n",
    "regions = regionprops(label_image.cpu().numpy())\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.imshow(image_label_overlay)\n",
    "for i, region in enumerate(regions):\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red' if sel_idx is not None and i==sel_idx else 'green', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(minc, minr-1, i+1, color='g', fontweight='bold')\n",
    "for i, (x, y) in enumerate(soma_coords):\n",
    "    ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "    ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# num_labels = label_image.max().item()\n",
    "# fig, ax = plt.subplots(num_labels, figsize=(20, 10*num_labels))\n",
    "# for i in range(len(traces)):\n",
    "#     ax[i].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[i].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[i].legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# num_labels = len(good_box_idx)\n",
    "# fig, ax = plt.subplots(num_labels, 2, figsize=(20, 10*num_labels))\n",
    "# for k, (i, j) in enumerate(zip(good_box_idx.tolist(), soma_idx.tolist())):\n",
    "#     ax[k, 0].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[k, 0].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[k, 0].legend()\n",
    "#     ax[k, 0].set_title(f'Box {i+1}')\n",
    "#     ax[k, 1].plot(true_traces[j].cpu(), 'g-', label='true')\n",
    "#     ax[k, 1].legend()\n",
    "#     ax[k, 1].set_title(f'Neuron {j+1}')\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_label_idx = 4\n",
    "split_clusters(sel_label_idx, denoised_mat, label_image, cor_threshold=0.8, min_num_pixels=50, max_dist=2,\n",
    "              median_detrend=True, apply_fft=True, fft_max_freq=200, verbose=True, plot=True, soma_coords=soma_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_label_idx = 1\n",
    "while sel_label_idx <= label_image.max():\n",
    "    print(sel_label_idx)\n",
    "    split_clusters(sel_label_idx, denoised_mat, label_image, cor_threshold=0.8, min_num_pixels=50, max_dist=2,\n",
    "                  median_detrend=True, apply_fft=True, fft_max_freq=200, verbose=True)\n",
    "    sel_label_idx += 1\n",
    "bincount = torch.bincount(label_image.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = regionprops(label_image.cpu().numpy())\n",
    "box_coords = soma_coords.new_tensor(np.array([region.bbox for region in regions]))[:, [1, 3, 0, 2]]\n",
    "box_coords = box_coords.reshape(box_coords.shape[0], box_coords.shape[1]//2, 2)\n",
    "selected = mark_points_in_intervals(soma_coords, box_coords)\n",
    "false_negatives = [i+1 for i in torch.nonzero(selected.sum(1) == 0, as_tuple=True)[0].tolist()]\n",
    "false_positives = [i+1 for i in torch.nonzero(selected.sum(0) == 0, as_tuple=True)[0].tolist()]\n",
    "print('False Negatives (missed {} neurons): {}'.format(len(false_negatives), false_negatives))\n",
    "print('False Positives ({} empty boxes): {}'.format(len(false_positives), false_positives))\n",
    "good_box_idx = torch.nonzero(selected.sum(0)==1, as_tuple=True)[0]\n",
    "soma_idx = torch.nonzero(selected[:, good_box_idx].T, as_tuple=True)[1]\n",
    "print('{} good boxes: {}'.format(len(good_box_idx), [(i+1, j+1) for i, j in zip(good_box_idx.tolist(), soma_idx.tolist())]))\n",
    "\n",
    "figsize = (20, 10)\n",
    "sel_idx = None\n",
    "image_label_overlay = label2rgb(label_image.cpu().numpy(), image=cor_map.cpu().numpy())\n",
    "regions = regionprops(label_image.cpu().numpy())\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.imshow(image_label_overlay)\n",
    "for i, region in enumerate(regions):\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red' if sel_idx is not None and i==sel_idx else 'green', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(minc, minr-1, i+1, color='g', fontweight='bold')\n",
    "for i, (x, y) in enumerate(soma_coords):\n",
    "    ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "    ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# num_labels = label_image.max().item()\n",
    "# fig, ax = plt.subplots(num_labels, figsize=(20, 10*num_labels))\n",
    "# for i in range(len(traces)):\n",
    "#     ax[i].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "#     ax[i].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "#     ax[i].legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "submats, traces = extract_traces(mat, softmask=cor_map, label_image=label_image, regions=None, median_detrend=median_detrend)\n",
    "denoised_submats, denoised_traces = extract_traces(denoised_mat, softmask=cor_map, label_image=label_image, regions=None, \n",
    "                                                   median_detrend=median_detrend)\n",
    "num_labels = len(good_box_idx)\n",
    "fig, ax = plt.subplots(num_labels, 2, figsize=(20, 10*num_labels))\n",
    "for k, (i, j) in enumerate(zip(good_box_idx.tolist(), soma_idx.tolist())):\n",
    "    ax[k, 0].plot(traces[i].cpu(), 'b-', alpha=0.5, label=f'{i+1} raw')\n",
    "    ax[k, 0].plot(denoised_traces[i].cpu(), 'r-', alpha=0.5, label=f'{i+1} denoised')\n",
    "    ax[k, 0].legend()\n",
    "    ax[k, 0].set_title(f'Box {i+1}')\n",
    "    ax[k, 1].plot(true_traces[j].cpu(), 'g-', label='true')\n",
    "    ax[k, 1].legend()\n",
    "    ax[k, 1].set_title(f'Neuron {j+1}')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_label_overlay(cor_map, label_image=label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel_label_idx in range(1, label_image.max()+1):\n",
    "    # minr, minc, maxr, maxc = regions[sel_label_idx-1].bbox\n",
    "    # submat = mat[:, minr:maxr, minc:maxc]\n",
    "    coords = torch.from_numpy(np.stack(np.nonzero(label_image == sel_label_idx), axis=1)).to(device)\n",
    "    m = denoised_mat[:, coords[:, 0], coords[:, 1]]\n",
    "\n",
    "    dist = manhattan_distance(coords)\n",
    "    dist.fill_diagonal_(999)\n",
    "    adj_mat = (dist <= 2)\n",
    "\n",
    "    fft = torch.rfft(m.T, signal_ndim=1, normalized=True).reshape(m.size(1), -1)\n",
    "    fft = fft - fft.mean(1, keepdim=True)\n",
    "    norm = torch.norm(fft, dim=1)\n",
    "    cor = torch.mm(fft, fft.T) / (norm.unsqueeze(1) * norm)\n",
    "    cor[~adj_mat] = 0\n",
    "\n",
    "    laplacian = graph_laplacian(cor)\n",
    "    eigenvalues, eigenvectors = torch.symeig(laplacian, eigenvectors=True)\n",
    "    # fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    # ax.set_title(sel_label_idx)\n",
    "    # ax.plot(eigenvalues.tolist()[:50], 'o-')\n",
    "    # ax.axvline(x=len(torch.nonzero(selected[:, sel_label_idx-1], as_tuple=True)[0]))\n",
    "    # plt.show()\n",
    "\n",
    "    k = 2\n",
    "    labels, dist = k_means(eigenvectors[:,:k], k)\n",
    "    image = torch.zeros_like(cor_map)\n",
    "    image[coords[:, 0], coords[:, 1]] = image.new_tensor(labels+1)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image.cpu().numpy())\n",
    "    ax.set_title(f'{k} {dist.item()}')\n",
    "    for i, (x, y) in enumerate(soma_coords):\n",
    "        ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "        ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    neuron_idx = torch.nonzero(selected[:, sel_label_idx-1], as_tuple=True)[0]\n",
    "    x = torch.stack([m[:, labels==i].mean(1) for i in range(2)], dim=0)\n",
    "    y = true_traces[neuron_idx]\n",
    "    print(simple_cosine_similarity(x[:1], x[1:]).item())\n",
    "    print(simple_cosine_similarity(x, y).tolist())\n",
    "    fig, ax = plt.subplots(2, figsize=(20, 20))\n",
    "    for i in range(2):\n",
    "        ax[0].plot(x[i].cpu(), label=i+1)\n",
    "    for i, j in enumerate(neuron_idx):\n",
    "        ax[1].plot(y[i].cpu(), label=j.item()+1)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 30, 3)\n",
    "ds = []\n",
    "for k in ks:\n",
    "    labels, dist = k_means(eigenvectors[:,:k], k)\n",
    "    image = torch.zeros_like(cor_map)\n",
    "    image[coords[:, 0], coords[:, 1]] = image.new_tensor(labels+1)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(image.cpu().numpy())\n",
    "    ax.set_title(f'{k} {dist.item()}')\n",
    "    for i, (x, y) in enumerate(soma_coords):\n",
    "        ax.scatter([x.item()], [y.item()], s=30, c='r')\n",
    "        ax.text(x.item()+1, y.item(), i+1, color='r', fontweight='bold')\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    ds.append(dist.item())\n",
    "\n",
    "plt.plot(ks, ds, 'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import simple_linear_regression\n",
    "for i, j in zip(good_box_idx, soma_idx):\n",
    "    i = i.item()\n",
    "    j = j.item()\n",
    "    print(f'Box {i+1}, Soma {j+1}')\n",
    "    print('cor(raw, denoised) = {:.2f}'.format(nn.functional.cosine_similarity(traces[i], traces_denoised[i], dim=0).item()))\n",
    "    print('cor(raw, true) = {:.2f}'.format(nn.functional.cosine_similarity(traces[i], true_traces[j], dim=0)))\n",
    "    print('cor(denoised, true) = {:.2f}'.format(nn.functional.cosine_similarity(traces_denoised[i], true_traces[j], dim=0)))\n",
    "    fig, ax = plt.subplots(3)\n",
    "    ax[0].plot(traces[i].cpu(), label='raw', alpha=0.5, c='b')\n",
    "    ax[0].plot(traces_denoised[i].cpu(), label='denoised', c='r')\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(true_traces[j].cpu(), c='g', label='true')\n",
    "    ax[1].legend()\n",
    "    ax[2].plot(simple_linear_regression(traces[i], true_traces[j], return_fitted=True).cpu(), label='raw', alpha=0.5, c='b')\n",
    "    ax[2].plot(simple_linear_regression(traces_denoised[i], true_traces[j], return_fitted=True).cpu(), label='denoised', alpha=0.5, c='r')\n",
    "    ax[2].plot(true_traces[j].cpu(), c='g', alpha=0.5, label='true')\n",
    "    ax[2].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = adaptive_avg_pool(mat, (256, nrow, ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rfft(m.transpose(0, 2), signal_ndim=1, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = get_cor_map(m.transpose(1, 2).transpose(0, 3).reshape(-1, 180, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(cor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(adaptive_avg_pool(m, label_image.shape))\n",
    "imshow(label_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_label = 8\n",
    "idx1, idx2 = np.nonzero(label_image==sel_label)\n",
    "order = cor_map[idx1, idx2].sort()[1].tolist()\n",
    "idx1, idx2 = idx1[order], idx2[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = denoised_mat[:, idx1, idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.rfft((m - m.mean(0)).T, 1, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[:, 250:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.irfft(f, 1, normalized=True, signal_sizes=[1000]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m2[:, 0].cpu())\n",
    "plt.show()\n",
    "plt.plot(m[:, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f[0, :, 0].cpu())\n",
    "plt.show()\n",
    "plt.plot(f[0, :, 1].cpu())\n",
    "plt.show()\n",
    "plt.plot(m[:, 0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_somas = selected.sum(0)\n",
    "for i in range(1, label_image.max()+1):\n",
    "    idx1, idx2 = np.nonzero(label_image==i)\n",
    "    m = mat[:, idx1, idx2]\n",
    "    with torch.no_grad():\n",
    "        u, s, v = torch.svd(m)\n",
    "    plt.plot(s[1:].cpu(), 'o-')\n",
    "    plt.title('{}: {}: {}'.format(i+1, num_somas[i-1].item(), s[:5].tolist()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_somas = selected.sum(0)\n",
    "for i, submat in enumerate(submats):\n",
    "    m = adaptive_avg_pool(submat, (256, 16, 16)).reshape(256, 256)\n",
    "    with torch.no_grad():\n",
    "        eigenvalues, eigenvectors = torch.eig(m)\n",
    "        eigenvalues = torch.norm(eigenvalues, dim=1)\n",
    "    plt.plot(eigenvalues.cpu()[1:], 'o-')\n",
    "    plt.title('{}: {}: {}'.format(i+1, num_somas[i].item(), eigenvalues[:5].tolist()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "submats[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_maps = [get_cor_map(m) for m in [mat, denoised_mat, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = target\n",
    "noisy = m + torch.randn_like(m) * m.std()*0.1\n",
    "cor = get_cor_map(noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(masks.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder = f'{data_folder}/individual_neurons'\n",
    "if not os.path.exists(fig_folder):\n",
    "    print(f'Create {fig_folder}')\n",
    "    os.makedirs(fig_folder)\n",
    "if not os.path.exists(f'{fig_folder}/individual_neurons.gif'):\n",
    "    for i in range(len(masks)):\n",
    "        y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        im = ax.imshow(cor_map.cpu().numpy(), cmap='gray')\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        fig.colorbar(im, cax=cax)\n",
    "        ax.scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.5)\n",
    "        ax.scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "        ax.set_title(f'Neuron {i} (soma is red)')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f'{fig_folder}/{i}.png')\n",
    "        plt.close()\n",
    "    save_gif_file(imgs=[f'{fig_folder}/{i}.png' for i in range(len(masks))], save_path=f'{fig_folder}/individual_neurons.gif')\n",
    "\n",
    "    img = masks.sum(0).cpu()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    im = ax.imshow(img, cmap=matplotlib.cm.get_cmap('viridis', img.max()+1))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    ax.scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r', s=20, alpha=0.5)\n",
    "    ax.set_title('Overlapping of neurons (red dots are somas)')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{fig_folder}/overlapping.png')\n",
    "    plt.show()\n",
    "    \n",
    "if not os.path.exists(f'{fig_folder}/individual_neurons_with_spikes.gif'):\n",
    "    for i in range(len(masks)):\n",
    "        y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "        fig, ax = plt.subplots(2, figsize=(16, 16))\n",
    "        im = ax[0].imshow(cor_map.cpu().numpy(), cmap='gray')\n",
    "        divider = make_axes_locatable(ax[0])\n",
    "        cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "        fig.colorbar(im, cax=cax)\n",
    "        ax[0].scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.5)\n",
    "        ax[0].scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "        ax[0].set_title(f'Neuron {i} (soma is red)')\n",
    "        ax[1].plot(traces[i].cpu())\n",
    "        ax[1].set_title(f'Neuron {i} mean fluorescence trace')\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f'{fig_folder}/{i}.png')\n",
    "        plt.close()\n",
    "    save_gif_file(imgs=[f'{fig_folder}/{i}.png' for i in range(len(masks))], save_path=f'{fig_folder}/individual_neurons_with_spikes.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = get_cor_map(mat, topk=5)\n",
    "label_image, regions = get_label_image(cor_map, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()\n",
    "soft_mask, model = semi_supervised_segmentation(mat, cor_map=cor_map, model=None, out_channels=[8,8,8,8], \n",
    "                                                kernel_size=3, frames_per_iter=100, num_iters=100, \n",
    "                                                print_every=20, select_frames=False, optimizer_fn=torch.optim.AdamW, \n",
    "                                                optimizer_fn_args = {'lr': 1e-2, 'weight_decay': 1e-3}, \n",
    "                                                save_loss_folder=None, loss_threshold=0, reduction='mean',\n",
    "                                                last_out_channels=None,\n",
    "                                                return_model=True, verbose=True)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(cor_map)\n",
    "imshow(soft_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "frames_per_iter = 100\n",
    "num_iters = 10\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    soft_masks = []\n",
    "    starts = []\n",
    "    for i in range(num_iters):\n",
    "        start = np.random.choice(901)\n",
    "        starts.append(start)\n",
    "        x = mat[start:start+frames_per_iter]\n",
    "        y_pred = model(x).mean(1)\n",
    "        soft_mask = torch.softmax(y_pred, dim=0)[1]\n",
    "        soft_masks.append(soft_mask)\n",
    "end_time = time.time()\n",
    "print(f'Time spent: {end_time - start_time}')\n",
    "soft_mask = torch.stack(soft_masks, dim=0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(starts):\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].plot(mat[s:s+frames_per_iter].mean((1,2)).cpu())\n",
    "    ax[0].set_title(f'{s}-{s+frames_per_iter}')\n",
    "    im = ax[1].imshow(soft_masks[i].cpu().numpy())\n",
    "    divider = make_axes_locatable(ax[1])\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(soft_mask.cpu(), cmap='Reds', alpha=0.5)\n",
    "plt.imshow(cor_map.cpu(), cmap='Blues', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_mask = torch.stack(soft_masks, dim=0).mean(0)\n",
    "imshow(soft_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(masks)):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    im = ax.imshow(soft_mask.cpu().numpy(), cmap='gray', alpha=1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "    ax.scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.2)\n",
    "    ax.scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "    ax.set_title(f'Neuron {i} (soma is red)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "im = ax.imshow(soft_mask.cpu().numpy(), cmap='gray', alpha=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "for i in range(len(masks)):\n",
    "    y, x = torch.nonzero(masks[i], as_tuple=True)\n",
    "    ax.scatter(x.cpu().numpy(), y.cpu().numpy(), c='g', s=3, alpha=0.2)\n",
    "for i in range(len(masks)):\n",
    "    ax.scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r', alpha=0.5)\n",
    "ax.set_title(f'Neuron masks (soma is red)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "import matplotlib.patches as mpatches\n",
    "bounding_box = True\n",
    "img = label2rgb(label_image, image=cor_map.cpu())\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "im = ax.imshow(img)\n",
    "if bounding_box:\n",
    "    for i, region in enumerate(regions):\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='green', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(minc, minr, i+1, color='r')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax.scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r', s=20, alpha=0.5)\n",
    "for i, (x, y) in enumerate(soma_coords):\n",
    "    ax.text(x, y, i, color='b')\n",
    "ax.set_title('Basic pipeline segmentation')\n",
    "ax.set_axis_off()\n",
    "fig.tight_layout()\n",
    "# if not os.path.exists(f'{fig_folder}/segmentation_basic.png'):\n",
    "#     plt.savefig(f'{fig_folder}/segmentation_basic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = 1\n",
    "num_components = 4\n",
    "minr, minc, maxr, maxc = regions[label_idx-1].bbox\n",
    "selected_frame_slice = slice(100, 700)\n",
    "selected_row_slice = slice(minr, maxr)\n",
    "selected_col_slice = slice(minc, maxc)\n",
    "selected_indices = (selected_frame_slice, selected_row_slice, selected_col_slice)\n",
    "\n",
    "submat = denoised_mat[selected_indices]\n",
    "mask = None\n",
    "# sub_cor_map = get_cor_map(submat)\n",
    "# sub_label_image, sub_regions = get_label_image(sub_cor_map, plot=True)\n",
    "\n",
    "\n",
    "# submat = denoised_mat[selected_frame_slice, label_image==label_idx]\n",
    "# mask = (label_image == label_idx)[selected_row_slice, selected_col_slice]\n",
    "\n",
    "W, H = plain_nmf(submat, n=num_components, mask=mask, fig_folder=None, save_npy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 31\n",
    "# plt.plot(target[selected_frame_slice, soma_coords[neuron_idx, 1], soma_coords[neuron_idx, 0]].cpu())\n",
    "plt.plot(traces[neuron_idx, selected_frame_slice].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '2d-noise2self_with_features'\n",
    "filepath = f'{save_folder}/denoised_movie_full_step64000.npy'\n",
    "pred = torch.from_numpy(np.load(filepath)).float().to(device)\n",
    "select_idx = range(100, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_name = 'median-5'\n",
    "pred_filtered = get_local_median(pred, window_size=15, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f'{save_folder}/mb-spike/spike.npy'\n",
    "spike_name = 'mb-spike'\n",
    "pred_filtered = torch.from_numpy(np.load(filepath)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_video_ffmpeg(torch.cat([scale_and_shift(m, scale=255) \n",
    "                             for m in [target[select_idx], pred[select_idx], pred_filtered[[select_idx]]]], dim=1), \n",
    "                  f'{spike_name}.avi', \n",
    "                  normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pred_filtered[select_idx].reshape(600, -1).cpu().numpy()\n",
    "min_val = M.min()\n",
    "M = M - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "ns = [51]\n",
    "fig_folder = f'{save_folder}/nmf_spike/{spike_name}'\n",
    "if not os.path.exists(fig_folder):\n",
    "    print(f'Creat folder {fig_folder}')\n",
    "    os.makedirs(fig_folder)\n",
    "for n in ns:\n",
    "    start_time = time.time()\n",
    "    model = NMF(n_components=n, init='random', random_state=0)\n",
    "    W = model.fit_transform(M)\n",
    "    H = model.components_\n",
    "    end_time = time.time()\n",
    "    print(n, end_time - start_time)\n",
    "    np.save(f'{fig_folder}/w_{n}.npy', W)\n",
    "    np.save(f'{fig_folder}/h_{n}.npy', H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(H.shape[0]):\n",
    "    fig, ax = plt.subplots(2, figsize=(20, 15))\n",
    "    ax[0].set_title(f'Component {i+1}')\n",
    "    im = ax[0].imshow(H[i].reshape(180, 512))\n",
    "    divider = make_axes_locatable(ax[0])\n",
    "    cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    ax[1].plot(W[:, i])\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'{fig_folder}/{i}.png')\n",
    "    plt.close()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageSequence\n",
    "# Create the frames\n",
    "frames = []\n",
    "imgs = [f'{fig_folder}/{n}.png' for n in range(H.shape[0])]\n",
    "for i in imgs:\n",
    "    new_frame = Image.open(i)\n",
    "    frames.append(new_frame)\n",
    "frames[0].save(f'{fig_folder}/nmf.gif', format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=1500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_map = get_cor_map(mat, topk=4)\n",
    "target = clean - trend\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(16, 21))\n",
    "im = ax[0].imshow(cor_map.cpu().numpy())\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[0].scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r')\n",
    "ax[0].set_title('correlation map of noisy video (red dots are somas)')\n",
    "im = ax[1].imshow(target.mean(0).cpu().numpy())\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[1].scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r')\n",
    "ax[1].set_title('temporal mean of the clean video (red dots are somas)')\n",
    "im = ax[2].imshow(clean.mean(0).cpu().numpy())\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "ax[2].scatter(soma_coords[:, 0].cpu().numpy(), soma_coords[:, 1].cpu().numpy(), c='r')\n",
    "ax[2].set_title('temporal mean of the clean video (before detrending)')\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{data_folder}/cor_map.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(10, 5, figsize=(20, 30))\n",
    "for i in range(50):\n",
    "    x, y = i//5, i%5\n",
    "    ax[x, y].imshow((cor_map*masks[i].float()).cpu().numpy())\n",
    "    ax[x, y].set_title(f'{i}')\n",
    "    ax[x, y].scatter(soma_coords[i, 0].cpu().numpy(), soma_coords[i, 1].cpu().numpy(), c='r')\n",
    "fig.tight_layout()\n",
    "plt.title('Individual neurons on correlation map')\n",
    "plt.savefig(f'{data_folder}/individual_neurons_cor_map.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 30))\n",
    "plt.plot(traces.T.cpu())\n",
    "plt.title('Neuron mean fluorescence')\n",
    "plt.savefig(f'{data_folder}/individual_neurons_mean_fluorescence.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_traces = torch.stack([mat[:, mask].mean(dim=1) for mask in masks], dim=1).T.cpu().numpy()\n",
    "clean_traces = torch.stack([target[:, mask].mean(dim=1) for mask in masks], dim=1).T.cpu().numpy()\n",
    "step = np.max(clean_traces.max(1) - clean_traces.min(1))\n",
    "fig, ax = plt.subplots(figsize=(10, 80))\n",
    "for i in range(len(raw_traces)):\n",
    "    ax.plot(raw_traces[i] - i*step, 'g-.', markersize=1, alpha=0.8, label='noisy' if i==0 else None)\n",
    "    ax.plot(clean_traces[i] - i*step, 'r-', markersize=1, alpha=0.5, label='clean' if i==0 else None)\n",
    "    ax.text(-30, -i*step, f'{i+1}')\n",
    "ax.set_ylim(-step*len(raw_traces), step)\n",
    "ax.legend()\n",
    "ax.set_title('Mean traces (noisy and clean)')\n",
    "plt.savefig(f'{data_folder}/mean_traces.png')\n",
    "plt.show()\n",
    "\n",
    "raw_traces = mat[:, mask_soma].T.cpu().numpy()\n",
    "clean_traces = target[:, mask_soma].T.cpu().numpy()\n",
    "step = np.max(clean_traces.max(1) - clean_traces.min(1))\n",
    "fig, ax = plt.subplots(figsize=(10, 80))\n",
    "for i in range(len(raw_traces)):\n",
    "    ax.plot(raw_traces[i] - i*step, 'g-.', markersize=1, alpha=0.8, label='noisy' if i==0 else None)\n",
    "    ax.plot(clean_traces[i] - i*step, 'r-', markersize=1, alpha=0.5, label='clean' if i==0 else None)\n",
    "    ax.text(-30, -i*step, f'{i+1}')\n",
    "ax.set_ylim(-step*len(raw_traces), step)\n",
    "ax.legend()\n",
    "ax.set_title('Soma traces (noisy and clean)')\n",
    "plt.savefig(f'{data_folder}/soma_traces.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'cp', f'{data_folder}/*png', f'gs://tma-opp-test/optosynth/optosynth_test_mb/data/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'cellmincer-with_global_features_mse'\n",
    "if not os.path.exists(save_folder):\n",
    "    print(f'Download folder gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}')\n",
    "    command = ['gsutil', '-m', 'cp', '-r', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}', '.']\n",
    "    response = subprocess.run(command, capture_output=True)\n",
    "    assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_folder)\n",
    "movie_start_idx = 100\n",
    "movie_end_idx = 700\n",
    "if re.search('cellmincer', save_folder):\n",
    "    num_epochs = 80\n",
    "    if re.search('epochs', save_folder):\n",
    "        num_epochs = int(save_folder[-8:-6])\n",
    "    num_iters = 1000\n",
    "else:\n",
    "    with open(f'{save_folder}/config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    num_episodes = len([k for k in config.keys() if re.search('^episode', k)])\n",
    "    num_epochs = sum([config[f'episode{e}']['train_settings']['num_epochs'] for e in range(num_episodes)])\n",
    "    num_iters = config['episode0']['train_settings']['num_iters']\n",
    "print(num_iters, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (clean-trend)[movie_start_idx:movie_end_idx]\n",
    "if not os.path.exists(f'{data_folder}/movie_frame{movie_start_idx}to{movie_end_idx}_clean.avi'):\n",
    "    print(f'Make video {data_folder}/movie_frame{movie_start_idx}to{movie_end_idx}_clean.avi')\n",
    "    make_video_ffmpeg(target, save_path=f'{data_folder}/movie_frame{movie_start_idx}to{movie_end_idx}_clean.avi')\n",
    "losses = []\n",
    "losses_train = []\n",
    "for epoch in range(num_epochs):\n",
    "    pred = target.new_tensor(\n",
    "        np.load(f'{save_folder}/denoised_movie_frame{movie_start_idx}to{movie_end_idx}_step{num_iters * (epoch+1)}.npy', allow_pickle=True))\n",
    "    losses.append([get_loss(pred, target, mask=None),\n",
    "                   get_loss(pred, target, mask=mask_cell),\n",
    "                   get_loss(pred, target, mask=mask_soma),\n",
    "                   get_loss(pred, target, mask=~mask_cell)])\n",
    "    losses_train.append([get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=None),\n",
    "                   get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=mask_cell),\n",
    "                   get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=mask_soma),\n",
    "                   get_loss(pred, mat[movie_start_idx:movie_end_idx], mask=~mask_cell)])\n",
    "    print(epoch, losses[-1])\n",
    "    print(epoch, losses_train[-1])\n",
    "save_path = f'{save_folder}/diff_movie_frame{movie_start_idx}to{movie_end_idx}_step{num_iters * (epoch+1)}.avi'\n",
    "make_video_ffmpeg(pred - target, \n",
    "                  save_path=save_path)\n",
    "command = ['gsutil', 'cp', save_path, f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0\n",
    "losses = np.array(losses)\n",
    "pandas.DataFrame(losses, columns=['all', 'cell', 'soma', 'background']).to_pickle(f'{save_folder}/rmse_losses.pkl')\n",
    "losses_train = np.array(losses_train)\n",
    "pandas.DataFrame(losses_train, columns=['all', 'cell', 'soma', 'background']).to_pickle(f'{save_folder}/rmse_losses_train.pkl')\n",
    "fig, ax = plt.subplots(5, sharex=True, figsize=(10, 20))\n",
    "ax[0].plot(losses[:, 0], 'ro-', label='all')\n",
    "ax[0].legend()\n",
    "ax[1].plot(losses[:, 1], 'bo-', label='cell')\n",
    "ax[1].legend()\n",
    "ax[2].plot(losses[:, 2], 'go-', label='soma')\n",
    "ax[2].legend()\n",
    "ax[3].plot(losses[:, 3], 'ko-', label='background')\n",
    "ax[3].legend()\n",
    "ax[4].plot(losses[:, 0], 'ro-', label='all')\n",
    "ax[4].plot(losses[:, 1], 'bo-', label='cell')\n",
    "ax[4].plot(losses[:, 2], 'go-', label='soma')\n",
    "ax[4].plot(losses[:, 3], 'ko-', label='background')\n",
    "ax[4].legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{save_folder}/rmse_losses.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(5, sharex=True, figsize=(10, 20))\n",
    "ax[0].plot(losses_train[:, 0], 'ro-', label='all')\n",
    "ax[0].legend()\n",
    "ax[1].plot(losses_train[:, 1], 'bo-', label='cell')\n",
    "ax[1].legend()\n",
    "ax[2].plot(losses_train[:, 2], 'go-', label='soma')\n",
    "ax[2].legend()\n",
    "ax[3].plot(losses_train[:, 3], 'ko-', label='background')\n",
    "ax[3].legend()\n",
    "ax[4].plot(losses_train[:, 0], 'ro-', label='all')\n",
    "ax[4].plot(losses_train[:, 1], 'bo-', label='cell')\n",
    "ax[4].plot(losses_train[:, 2], 'go-', label='soma')\n",
    "ax[4].plot(losses_train[:, 3], 'ko-', label='background')\n",
    "ax[4].legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{save_folder}/rmse_losses_train.png')\n",
    "plt.show()\n",
    "\n",
    "command = ['gsutil', 'cp', f'{save_folder}/rmse*', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 3200\n",
    "# model.load_state_dict(torch.load(f'{save_folder}/model_step{i}.pt'))\n",
    "\n",
    "# mean_mat = mat.mean()\n",
    "# std_mat = mat.std()\n",
    "# denoised_mat = model_denoise(((mat - mean_mat) / std_mat)[movie_start_idx-frame_depth:movie_end_idx+frame_depth], model, ndim=ndim, frame_depth=frame_depth,\n",
    "#                                  normalize=False, batch_size=batch_size_eval, replicate_pad=False)\n",
    "# denoised_mat = denoised_mat * std_mat + mean_mat\n",
    "\n",
    "# np.save(f'{save_folder}/denoised_movie_frame100to700_step{i}.npy', denoised_mat.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '2d-noise2self_with_features'\n",
    "num_iters = 1600\n",
    "num_epochs = 40\n",
    "# save_folder = 'cellmincer-with_global_features'\n",
    "# num_iters = 1000\n",
    "# num_epochs = 80\n",
    "\n",
    "filepath = f'{save_folder}/denoised_movie_frame100to700_step{num_iters*num_epochs}.npy'\n",
    "if not os.path.exists(filepath):\n",
    "    command = ['gsutil', '-m', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{filepath}', filepath]\n",
    "    response = subprocess.run(command, capture_output=True)\n",
    "    assert response.returncode == 0\n",
    "pred = target.new_tensor(np.load(filepath))\n",
    "# cor_map = get_cor_map(pred)\n",
    "# imshow(cor_map, title='correlation map of predicted video', save_file=f'{save_folder}/cor_map_pred_{num_epochs}epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = clean - trend\n",
    "if re.search('cellmincer', save_folder):\n",
    "    pred = target.new_tensor(np.load(f'{save_folder}/denoised_movie_frame0to1000_step{num_iters*num_epochs}.npy'))\n",
    "else:\n",
    "    pred = target.new_tensor(np.load(f'{save_folder}/denoised_movie_full_step{num_iters*num_epochs}.npy'))\n",
    "cor_map = get_cor_map(pred-target, topk=4)\n",
    "fig, ax = plt.subplots(3, figsize=(20, 20))\n",
    "im = ax[0].imshow((pred-target).mean(0).cpu())\n",
    "ax[0].set_title('temporal mean of (pred - target)')\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "im = ax[1].imshow((pred-target).abs().mean(0).cpu())\n",
    "ax[1].set_title('temporal mean of |pred - target|')\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "im = ax[2].imshow(cor_map.cpu())\n",
    "ax[2].set_title('correlation map of (pred - target)')\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "fig.colorbar(im, cax=cax)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'{save_folder}/temporal_mean_difference_{num_epochs}epochs.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(16, 16))\n",
    "ax[0].set_title('spatial mean')\n",
    "ax[0].plot(pred.mean((1, 2)).cpu(), label='pred')\n",
    "ax[0].plot(target.mean((1,2)).cpu(), label='target')\n",
    "ax[0].legend()\n",
    "ax[1].plot((pred-target).abs().mean((1,2)).cpu(), label='|pred - target|')\n",
    "ax[1].legend()\n",
    "ax[2].plot((pred-target).mean((1,2)).cpu(), label='pred - target')\n",
    "ax[2].legend()\n",
    "plt.savefig(f'{save_folder}/spatial_mean_difference_{num_epochs}epochs.png')\n",
    "plt.show()\n",
    "\n",
    "raw_traces = mat[:, mask_soma].T.cpu().numpy()\n",
    "pred_traces = pred[:, mask_soma].T.cpu().numpy()\n",
    "clean_traces = target[:, mask_soma].T.cpu().numpy()\n",
    "step = np.max(clean_traces.max(1) - clean_traces.min(1))\n",
    "fig, ax = plt.subplots(figsize=(10, 80))\n",
    "for i in range(len(raw_traces)):\n",
    "    ax.plot(raw_traces[i] - i*step, 'b-', markersize=1, alpha=0.3, label='Input' if i==0 else None)\n",
    "    ax.plot(pred_traces[i] - i*step, 'g-', markersize=1, alpha=0.8, label='Prediction' if i==0 else None)\n",
    "    ax.plot(clean_traces[i] - i*step, 'r-', markersize=1, alpha=0.5, label='Target'if i==0 else None)\n",
    "    ax.text(-30, -i*step, f'{i+1}')\n",
    "ax.set_ylim(-step*len(clean_traces), step)\n",
    "ax.legend()\n",
    "ax.set_title('Predicted soma traces')\n",
    "plt.savefig(f'{save_folder}/denoised_soma_traces_{num_epochs}epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'cp', f'{save_folder}/*.png', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{save_folder}/']\n",
    "response = subprocess.run(command)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'ls', 'gs://tma-opp-test/optosynth/optosynth_test_mb/results/']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0\n",
    "folders = [f.split('/')[-2] for f in response.stdout.decode().split() if re.search('/$', f) and not re.search('figures|diff_movies', f)]\n",
    "movie_start_idx = 100\n",
    "movie_end_idx = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['2d-noise2self_with_features', '2d-noise2self_with_features_80epochs', '2d-noise2self_with_features_80epochs_2',\n",
    "           'cellmincer-with_global_features', 'cellmincer-with_global_features_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    if not os.path.exists(folder):\n",
    "        print(folder)\n",
    "        os.makedirs(folder)\n",
    "        command = ['gsutil', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/rmse_losses.pkl', folder]\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "        if not re.search('^cellmincer', folder):\n",
    "            command = ['gsutil', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/config.json', folder]\n",
    "            response = subprocess.run(command, capture_output=True)\n",
    "            assert response.returncode == 0\n",
    "    if re.search('cellmincer', folder):\n",
    "#         num_epochs = 80\n",
    "#         if re.search('epochs', folder):\n",
    "#             num_epochs = int(folder[-8:-6])\n",
    "        num_iters = 1000\n",
    "        command = ['gsutil', 'ls', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/denoised_movie_frame100to700*npy']\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "        num_epochs = max([int(s.split('step')[-1][:-4]) for s in response.stdout.decode().split()]) // num_iters\n",
    "    else:\n",
    "        if not os.path.exists(f'{folder}/config.json'):\n",
    "            command = ['gsutil', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{folder}/config.json', folder]\n",
    "            response = subprocess.run(command, capture_output=True)\n",
    "            assert response.returncode == 0\n",
    "        with open(f'{folder}/config.json', 'r') as f:\n",
    "            config = json.load(f)\n",
    "        num_episodes = len([k for k in config.keys() if re.search('^episode', k)])\n",
    "        num_epochs = sum([config[f'episode{e}']['train_settings']['num_epochs'] for e in range(num_episodes)])\n",
    "        num_iters = config['episode0']['train_settings']['num_iters']\n",
    "    print(folder, num_iters, num_epochs)\n",
    "\n",
    "    target = (clean-trend)[movie_start_idx:movie_end_idx]\n",
    "    filepath = f'{folder}/denoised_movie_frame{movie_start_idx}to{movie_end_idx}_step{num_iters*num_epochs}.npy'\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f'Download {filepath}')\n",
    "        command = ['gsutil', '-m', 'cp', f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/{filepath}', folder]\n",
    "        response = subprocess.run(command, capture_output=True)\n",
    "        assert response.returncode == 0\n",
    "    pred = target.new_tensor(np.load(filepath))\n",
    "    def normalize(mat, scale=255):\n",
    "        return (mat - mat.min()) / (mat.max() - mat.min()) * scale\n",
    "#     if not os.path.exists(f'diff_movies/{folder}.avi'):\n",
    "#         print(f'Make video diff_movies/{folder}.avi')\n",
    "#         make_video_ffmpeg(torch.cat([normalize(pred), normalize(target), normalize(pred-target)], dim=1), \n",
    "#                           save_path=f'diff_movies/{folder}.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_good_colors()\n",
    "\n",
    "def get_label(model_name):\n",
    "    if model_name.startswith('2d-noise2self') and not model_name.endswith('with_features'):\n",
    "        return '2d-noise2self'\n",
    "    elif model_name.startswith('3d-noise2self'):\n",
    "        return '3d-noise2self'\n",
    "    else:\n",
    "        return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder = 'new-figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['2d-noise2self', '3d-noise2self', 'separate-net', 'cellmincer-with_global_features', 'cellmincer-wo_global_features']\n",
    "# model_names = ['2d-noise2self_2', '3d-noise2self_crop', 'separate-net']\n",
    "# model_names += [folder for folder in folders \n",
    "#                if (re.search('cellmincer', folder)\n",
    "#                    or folder in ['2d-noise2self_with_features'])]\n",
    "# model_names += ['cellmincer-with_global_features', 'cellmincer-wo_global_features']\n",
    "# model_names = [folder for folder in folders \n",
    "#                if (re.search('cellmincer', folder) and not re.search('wo', folder)\n",
    "#                    or folder in ['2d-noise2self_with_features'])]\n",
    "# model_names = ['2d-noise2self_with_features', \n",
    "#                'cellmincer-with_global_features', \n",
    "#                'cellmincer-with_global_features_mse',\n",
    "#               ]\n",
    "\n",
    "model_names = ['2d-noise2self_with_features', '2d-noise2self_with_features_80epochs_2', \n",
    "               'cellmincer-with_global_features', 'cellmincer-with_global_features_80epochs', \n",
    "               'cellmincer-with_global_features_mse',\n",
    "               'cellmincer-with_global_features_mse_80epochs'\n",
    "              ]\n",
    "# model_names = folders\n",
    "roi_names = ['RMSE of all pixels', 'RMSE of masked neuronal pixels', 'RMSE of 50 soma pixels', 'RMSE of background pixels']\n",
    "# colors = ['r', 'g', 'b', 'k', 'c']\n",
    "losses = [pandas.read_pickle(f'{model_name}/rmse_losses.pkl').values for model_name in model_names]\n",
    "fig_folder = 'figures'\n",
    "fig, ax = plt.subplots(len(roi_names), figsize=(20, 20))\n",
    "for j, roi_name in enumerate(roi_names):\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        y = losses[i][range(40) if re.search('2d-noise2self', model_name) else range(80), j]\n",
    "        x = range(1, len(y)+1)\n",
    "        ax[j].plot(x, y, 'o--' if re.search('wo', model_name) else 'o-', color=colors[i], label=model_name.split('_80epochs')[0])\n",
    "        ax[j].set_title(roi_name)\n",
    "        ax[j].set_xlabel('Epoch')\n",
    "        ax[j].set_ylabel('RMSE')\n",
    "        ax[j].legend()\n",
    "fig.tight_layout()\n",
    "# plt.savefig(f'{fig_folder}/five_models.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer-w-wo-features.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer-mse-losses.png')\n",
    "# plt.savefig(f'{fig_folder}/2d-noise2self-with-features.png')\n",
    "# plt.savefig(f'{fig_folder}/2d-noise2self-with-features_all.png')\n",
    "# plt.savefig(f'{fig_folder}/all.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer_2d-noise2self.png')\n",
    "# plt.savefig(f'{fig_folder}/cellmincer_2d-noise2self_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = ['gsutil', 'cp', '-r', fig_folder, f'gs://tma-opp-test/optosynth/optosynth_test_mb/results/']\n",
    "response = subprocess.run(command, capture_output=True)\n",
    "assert response.returncode == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_start_idx = 100\n",
    "movie_end_idx = 700\n",
    "pred = mat[movie_start_idx:movie_end_idx]\n",
    "target = (clean - trend)[movie_start_idx:movie_end_idx]\n",
    "pretrain_loss = [get_loss(pred, target, mask=None), \n",
    " get_loss(pred, target, mask=mask_cell),\n",
    " get_loss(pred, target, mask=mask_soma),\n",
    " get_loss(pred, target, mask=~mask_cell)]\n",
    "\n",
    "roi_names = ['all', 'cell', 'soma', 'background']\n",
    "colors = ['r', 'g', 'b', 'k', 'c']\n",
    "fig, ax = plt.subplots(len(roi_names), figsize=(20, 20))\n",
    "for j, roi_name in enumerate(roi_names):\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        ax[j].plot([pretrain_loss[j]]+losses[i, :, j].tolist(), f'{colors[i]}o-', label=model_name)\n",
    "        ax[j].set_title(roi_name)\n",
    "        ax[j].legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
